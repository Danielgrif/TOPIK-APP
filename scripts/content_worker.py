# –ü–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∫–æ–º–∞–Ω–¥–æ–π:
# pip install -r ../requirements.txt

import os
import re
import sys
import time
import hashlib
import random
import logging
import threading
import asyncio
import argparse
from http.server import BaseHTTPRequestHandler, HTTPServer
from urllib.parse import urlparse, parse_qs, quote, unquote
from io import BytesIO
import json
import warnings

warnings.simplefilter(action='ignore', category=FutureWarning)

# –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è –∫–æ–Ω—Å–æ–ª–∏ (Windows fix)
if sys.platform == 'win32':
    try: sys.stdout.reconfigure(encoding='utf-8')
    except AttributeError: pass

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤ —Ñ–∞–π–ª log.txt
logging.basicConfig(
    handlers=[
        logging.FileHandler('log.txt', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ],
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# –û—Ç–∫–ª—é—á–∞–µ–º —à—É–º –æ—Ç HTTP-–∫–ª–∏–µ–Ω—Ç–æ–≤, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –æ—à–∏–±–∫–∏
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("httpcore").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º –ø–∞–∫–µ—Ç–∞–º (–Ω–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ Python –∏—Ö –Ω–µ –≤–∏–¥–∏—Ç)
import site
try:
    sys.path.append(site.getusersitepackages())
except AttributeError: pass

try:
    import requests
    import aiohttp
    from supabase import create_client, create_async_client
    from dotenv import load_dotenv
    import edge_tts # type: ignore
    from PIL import Image
    from google import generativeai as genai
except ImportError as e:
    logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫: {e}")
    logging.error("–í–µ—Ä–æ—è—Ç–Ω–æ, —Ñ–∞–π–ª—ã –±–∏–±–ª–∏–æ—Ç–µ–∫ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω—ã. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤—ã–ø–æ–ª–Ω–∏—Ç—å —ç—Ç—É –∫–æ–º–∞–Ω–¥—É –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:")
    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—É—Ç—å –∫ requirements.txt –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Å–∫—Ä–∏–ø—Ç–∞
    req_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "requirements.txt")
    logging.error(f'"{sys.executable}" -m pip install --force-reinstall -r "{req_path}"')
    sys.exit(1)

# –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å .env (—Å—Ç–∞–Ω–¥–∞—Ä—Ç) –∏–ª–∏ env (–µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–∞–∑–≤–∞–Ω –±–µ–∑ —Ç–æ—á–∫–∏)
# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å–∫—Ä–∏–ø—Ç–∞, —á—Ç–æ–±—ã —Ç–æ—á–Ω–æ –Ω–∞–π—Ç–∏ .env
script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(script_dir)
load_dotenv(os.path.join(project_root, ".env"))

if not os.getenv("SUPABASE_URL"):
    load_dotenv(os.path.join(project_root, "env"))

# 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∏
SUPABASE_URL = os.getenv("SUPABASE_URL") or os.getenv("VITE_SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_KEY") or os.getenv("SUPABASE_KEY") or os.getenv("VITE_SUPABASE_KEY") # –ù—É–∂–µ–Ω –∫–ª—é—á —Å –ø—Ä–∞–≤–∞–º–∏ –∑–∞–ø–∏—Å–∏!
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
MIN_FILE_SIZE = 500 # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –≤ –±–∞–π—Ç–∞—Ö (–∏—Å–∫–ª—é—á–∞–µ—Ç –ø—É—Å—Ç—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏)

# –û—á–∏—Å—Ç–∫–∞ –∫–ª—é—á–µ–π –æ—Ç –∫–∞–≤—ã—á–µ–∫, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å (—á–∞—Å—Ç–∞—è –ø—Ä–æ–±–ª–µ–º–∞ .env)
if SUPABASE_URL: SUPABASE_URL = SUPABASE_URL.replace('"', '').replace("'", "")
if SUPABASE_KEY: SUPABASE_KEY = SUPABASE_KEY.replace('"', '').replace("'", "")
if GEMINI_API_KEY: GEMINI_API_KEY = GEMINI_API_KEY.replace('"', '').replace("'", "")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–µ—Ñ–æ–ª—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
if GEMINI_API_KEY == "–≤–∞—à_–∫–ª—é—á_–∑–¥–µ—Å—å":
    GEMINI_API_KEY = None

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è –∏–º–µ–Ω —Ç–∞–±–ª–∏—Ü –∏ –±–∞–∫–µ—Ç–æ–≤
DB_TABLES = {
    "VOCABULARY": "vocabulary",
    "QUOTES": "quotes",
    "WORD_REQUESTS": "word_requests",
    "USER_PROGRESS": "user_progress",
    "LIST_ITEMS": "list_items",
}
DB_BUCKETS = {
    "AUDIO": "audio-files",
    "IMAGES": "image-files",
}
WORD_REQUEST_STATUS = {
    "PENDING": "pending",
    "PROCESSED": "processed",
    "ERROR": "error",
}

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —Ñ–ª–∞–≥–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å—Ö–µ–º—ã
HAS_GRAMMAR_INFO = True

if not SUPABASE_URL or not SUPABASE_KEY:
    logging.error("‚ùå –û–®–ò–ë–ö–ê: –ù–µ –Ω–∞–π–¥–µ–Ω—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è SUPABASE_URL –∏–ª–∏ SUPABASE_SERVICE_KEY (–∏–ª–∏ –∏—Ö VITE_ –∞–Ω–∞–ª–æ–≥–∏).")
    logging.error("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª .env —Å–æ–∑–¥–∞–Ω –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç —ç—Ç–∏ –∫–ª—é—á–∏.")
    sys.exit(1)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
parser = argparse.ArgumentParser(description="–§–æ–Ω–æ–≤—ã–π –≤–æ—Ä–∫–µ—Ä TOPIK APP: –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞—è–≤–æ–∫ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞")
parser.add_argument("--topic", type=str, help="–û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ —Å–ª–æ–≤–∞ –∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ç–µ–º—ã (—Ñ–∏–ª—å—Ç—Ä –ø–æ –∫–æ–ª–æ–Ω–∫–µ 'topic')")
parser.add_argument("--word", type=str, help="–û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ —Å–ª–æ–≤–æ (—Ñ–∏–ª—å—Ç—Ä –ø–æ 'word_kr')")
parser.add_argument("--force-images", action="store_true", help="–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å —Å—Ç–∞—Ä—ã–µ)")
parser.add_argument("--force-audio", action="store_true", help="–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å –∞—É–¥–∏–æ (–ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å —Å—Ç–∞—Ä—ã–µ)")
parser.add_argument("--force-quotes", action="store_true", help="–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å –∞—É–¥–∏–æ —Ç–æ–ª—å–∫–æ –¥–ª—è —Ü–∏—Ç–∞—Ç")
parser.add_argument("--check", action="store_true", help="–ó–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ —Ñ–∞–π–ª–æ–≤ –∏ —Å—Å—ã–ª–æ–∫ (—É–¥–∞–ª–µ–Ω–∏–µ –±–∏—Ç—ã—Ö)")
parser.add_argument("--retry-errors", action="store_true", help="–°–±—Ä–æ—Å–∏—Ç—å —Å—Ç–∞—Ç—É—Å –æ—à–∏–±–æ—á–Ω—ã—Ö –∑–∞—è–≤–æ–∫ –Ω–∞ 'pending' –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏")
parser.add_argument("--exit-after-maintenance", action="store_true", help="–ó–∞–≤–µ—Ä—à–∏—Ç—å —Ä–∞–±–æ—Ç—É –ø–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è")
parser.add_argument("--concurrency", type=int, default=0, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤ (0 = –∞–≤—Ç–æ-–ø–æ–¥–±–æ—Ä, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0)")
args = parser.parse_args()

# –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è "Storage endpoint URL should have a trailing slash"
if not SUPABASE_URL.endswith("/"):
    SUPABASE_URL += "/" # type: ignore

# –ü–∞—Ç—á –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—à–∏–±–∫–∏ "Storage endpoint URL should have a trailing slash"
try:
    StorageClient = None
    # –ü—Ä–æ–±—É–µ–º –ø—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ –≤–µ—Ä—Å–∏–π supabase-py v1
    try:
        from storage3.utils import StorageClient # type: ignore
    except ImportError:
        try:
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø—É—Ç—å –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π
            from storage3.client import StorageClient # type: ignore
        except ImportError:
            try:
                # –ï—â–µ –æ–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –≤–µ—Ä—Å–∏–π
                from storage3 import StorageClient # type: ignore
            except ImportError:
                pass

    if StorageClient is not None:
        _original_init = StorageClient.__init__
        def _patched_init(self, url, headers, *args, **kwargs):
            if url and not url.endswith("/"):
                url += "/"
            _original_init(self, url, headers, *args, **kwargs)
        StorageClient.__init__ = _patched_init
        logging.info("‚úÖ –ü–∞—Ç—á –¥–ª—è StorageClient —É—Å–ø–µ—à–Ω–æ –ø—Ä–∏–º–µ–Ω–µ–Ω.")
    else:
        logging.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ StorageClient. –ü–∞—Ç—á –ø—Ä–æ–ø—É—â–µ–Ω (–≤–æ–∑–º–æ–∂–Ω–æ, –æ–Ω –Ω–µ –Ω—É–∂–µ–Ω –≤ —ç—Ç–æ–π –≤–µ—Ä—Å–∏–∏).")
except Exception as e:
    logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–º–µ–Ω–∏—Ç—å –ø–∞—Ç—á –¥–ª—è StorageClient: {e}")

try:
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
except Exception as e:
    logging.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Supabase: {e}")
    logging.error("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ URL –∏ KEY –≤ —Ñ–∞–π–ª–µ .env")
    sys.exit(1)

def _execute_with_retry(executable):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∫ Supabase —Å –ª–æ–≥–∏–∫–æ–π –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫."""
    max_retries = 4
    base_delay = 1.5
    for attempt in range(max_retries):
        try:
            return executable.execute()
        except Exception as e:
            err_str = str(e).lower()
            is_network_error = 'getaddrinfo failed' in err_str or '10054' in err_str or 'timed out' in err_str or 'connection' in err_str or '10051' in err_str
            if is_network_error and attempt < max_retries - 1:
                delay = base_delay * (2 ** attempt) + random.uniform(0, 1)
                # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é –ø–æ–ø—ã—Ç–∫—É —Ä–µ—Ç—Ä–∞—è, —á—Ç–æ–±—ã –Ω–µ —Å–ø–∞–º–∏—Ç—å –≤ –∫–æ–Ω—Å–æ–ª—å –ø—Ä–∏ –º–∏–∫—Ä–æ-—Ä–∞–∑—Ä—ã–≤–∞—Ö
                if attempt == 0 or attempt == max_retries - 2:
                    logging.warning(f"üåê –°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ Supabase ({e}). –ü–æ–ø—ã—Ç–∫–∞ {attempt + 2}/{max_retries} —á–µ—Ä–µ–∑ {delay:.1f}—Å...")
                time.sleep(delay)
            else:
                raise e

async def execute_supabase_query(executable):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ Supabase —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏."""
    loop = asyncio.get_running_loop()
    # –ó–∞–ø—É—Å–∫–∞–µ–º –±–ª–æ–∫–∏—Ä—É—é—â–∏–π –≤—ã–∑–æ–≤ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ, —á—Ç–æ–±—ã –Ω–µ –∑–∞–º–æ—Ä–∞–∂–∏–≤–∞—Ç—å asyncio
    return await loop.run_in_executor(None, _execute_with_retry, executable)

# 1.1 –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –±–∞–∫–µ—Ç–∞ (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞)
try:
    buckets = supabase.storage.list_buckets()
    if not any(b.name == DB_BUCKETS['AUDIO'] for b in buckets):
        logging.info(f"üì¶ –ë–∞–∫–µ—Ç '{DB_BUCKETS['AUDIO']}' –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–æ–∑–¥–∞—é –Ω–æ–≤—ã–π –ø—É–±–ª–∏—á–Ω—ã–π –±–∞–∫–µ—Ç...")
        supabase.storage.create_bucket(DB_BUCKETS['AUDIO'], options={"public": True})
        logging.info(f"‚úÖ –ë–∞–∫–µ—Ç '{DB_BUCKETS['AUDIO']}' —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω.")
    else:
        logging.info(f"‚ÑπÔ∏è –ë–∞–∫–µ—Ç '{DB_BUCKETS['AUDIO']}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.")
except Exception as e:
    # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫—É, –µ—Å–ª–∏ –±–∞–∫–µ—Ç —É–∂–µ –µ—Å—Ç—å, –Ω–æ API –≤–µ—Ä–Ω—É–ª –æ—à–∏–±–∫—É –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞
    logging.warning(f"‚ö†Ô∏è –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–∫–µ—Ç–∞: {e}")

# 1.2 –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –±–∞–∫–µ—Ç–∞ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
try:
    buckets = supabase.storage.list_buckets()
    if not any(b.name == DB_BUCKETS['IMAGES'] for b in buckets):
        logging.info(f"üì¶ –ë–∞–∫–µ—Ç '{DB_BUCKETS['IMAGES']}' –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–æ–∑–¥–∞—é –Ω–æ–≤—ã–π –ø—É–±–ª–∏—á–Ω—ã–π –±–∞–∫–µ—Ç...")
        supabase.storage.create_bucket(DB_BUCKETS['IMAGES'], options={"public": True})
        logging.info(f"‚úÖ –ë–∞–∫–µ—Ç '{DB_BUCKETS['IMAGES']}' —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω.")
    else:
        # –ï—Å–ª–∏ –±–∞–∫–µ—Ç —É–∂–µ –µ—Å—Ç—å, —É–±–µ–¥–∏–º—Å—è, —á—Ç–æ –æ–Ω –ø—É–±–ª–∏—á–Ω—ã–π
        logging.info(f"‚ÑπÔ∏è –ë–∞–∫–µ—Ç '{DB_BUCKETS['IMAGES']}' –Ω–∞–π–¥–µ–Ω. –û–±–Ω–æ–≤–ª—è—é –ø—Ä–∞–≤–∞ –Ω–∞ Public...")
        supabase.storage.update_bucket(DB_BUCKETS['IMAGES'], {"public": True})
except Exception as e:
    logging.warning(f"‚ö†Ô∏è –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–∫–µ—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {e}")

# –°–ø–∏—Å–∫–∏ –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏ –≤—ã–≤–æ–¥–∞ AI
valid_topics = [
    "Daily Life (–ü–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–∞—è –∂–∏–∑–Ω—å)", "Economics (–≠–∫–æ–Ω–æ–º–∏–∫–∞)", "Politics (–ü–æ–ª–∏—Ç–∏–∫–∞)", 
    "Society (–û–±—â–µ—Å—Ç–≤–æ)", "Culture (–ö—É–ª—å—Ç—É—Ä–∞)", "Health (–ó–¥–æ—Ä–æ–≤—å–µ)", 
    "Environment (–ü—Ä–∏—Ä–æ–¥–∞/–≠–∫–æ–ª–æ–≥–∏—è)", "Science (–ù–∞—É–∫–∞)", "Education (–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ)", 
    "History (–ò—Å—Ç–æ—Ä–∏—è)", "Art (–ò—Å–∫—É—Å—Å—Ç–≤–æ)", "Sports (–°–ø–æ—Ä—Ç)", "Weather (–ü–æ–≥–æ–¥–∞)", 
    "Shopping (–ü–æ–∫—É–ø–∫–∏)", "Travel (–ü—É—Ç–µ—à–µ—Å—Ç–≤–∏—è)", "Food (–ï–¥–∞)", "Work (–†–∞–±–æ—Ç–∞)", 
    "Feelings (–ß—É–≤—Å—Ç–≤–∞)", "Personality (–•–∞—Ä–∞–∫—Ç–µ—Ä)", "Appearance (–í–Ω–µ—à–Ω–æ—Å—Ç—å)", 
    "Hobbies (–•–æ–±–±–∏)", "Other (–î—Ä—É–≥–æ–µ)"
]

valid_categories = [
    "Noun (–°—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ)", "Verb (–ì–ª–∞–≥–æ–ª)", "Adjective (–ü—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω–æ–µ)", 
    "Adverb (–ù–∞—Ä–µ—á–∏–µ)", "Particle (–ß–∞—Å—Ç–∏—Ü–∞)", "Suffix (–°—É—Ñ—Ñ–∏–∫—Å)", 
    "Pronoun (–ú–µ—Å—Ç–æ–∏–º–µ–Ω–∏–µ)", "Number (–ß–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ–µ)", "Interjection (–ú–µ–∂–¥–æ–º–µ—Ç–∏–µ)", 
    "Grammar (–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞)"
]


# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Gemini
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
else:
    logging.warning("‚ö†Ô∏è GEMINI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ AI –±—É–¥–µ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.")

if args.retry_errors:
    try:
        logging.info(f"üîÑ –°–±—Ä–æ—Å –∑–∞—è–≤–æ–∫ —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º '{WORD_REQUEST_STATUS['ERROR']}' –Ω–∞ '{WORD_REQUEST_STATUS['PENDING']}'...")
        res = supabase.table(DB_TABLES['WORD_REQUESTS']).update({'status': WORD_REQUEST_STATUS['PENDING']}).eq('status', WORD_REQUEST_STATUS['ERROR']).execute()
        count = len(res.data) if res.data else 0
        logging.info(f"‚úÖ –°–±—Ä–æ—à–µ–Ω–æ –∑–∞—è–≤–æ–∫: {count}")
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–±—Ä–æ—Å–∞ –∑–∞—è–≤–æ–∫: {e}")
    
    if args.exit_after_maintenance:
        logging.info("üèÅ –û–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –í—ã—Ö–æ–¥.")
        sys.exit(0)

def clean_query_for_pixabay(text):
    """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–≤–æ–¥–∞ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∏—Å–∫–∞ –∫–∞—Ä—Ç–∏–Ω–æ–∫."""
    if not text: return ""
    # –£–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –≤ —Å–∫–æ–±–∫–∞—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–∂–µ–Ω—â–∏–Ω–∞ (–≤–∑—Ä–æ—Å–ª–∞—è)")
    text = re.sub(r'\(.*?\)', '', text)
    # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é —á–∞—Å—Ç—å –¥–æ –∑–∞–ø—è—Ç–æ–π –∏–ª–∏ —Ç–æ—á–∫–∏ —Å –∑–∞–ø—è—Ç–æ–π
    text = re.split(r'[;,]', text)[0]
    return text.strip()

def clean_text_for_tts(text):
    """–£–¥–∞–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –≤ —Å–∫–æ–±–∫–∞—Ö (Hanja, –ø–æ—è—Å–Ω–µ–Ω–∏—è) –¥–ª—è —á–∏—Å—Ç–æ–≥–æ –æ–∑–≤—É—á–∏–≤–∞–Ω–∏—è."""
    if not text: return ""
    # –£–¥–∞–ª—è–µ–º (—Ç–µ–∫—Å—Ç) –∏ [—Ç–µ–∫—Å—Ç], –≤–∫–ª—é—á–∞—è –ø—Ä–æ–±–µ–ª –ø–µ—Ä–µ–¥ –Ω–∏–º–∏
    text = re.sub(r'\s*[\(\[].*?[\)\]]', '', text)
    return text.strip()

async def delete_old_file(bucket, url):
    """–£–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª –∏–∑ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π –Ω–æ–≤–æ–≥–æ"""
    if not url: return
    try:
        filename = unquote(url.split('/')[-1].split('?')[0])
        loop = asyncio.get_running_loop()
        
        def _do_delete():
            for i in range(3):
                try:
                    return supabase.storage.from_(bucket).remove([filename])
                except Exception as e:
                    if "10035" in str(e) or "10054" in str(e): time.sleep(0.5); continue
                    raise e

        await loop.run_in_executor(None, _do_delete)
        logging.info(f"üóë –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª: {filename}")
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª {url}: {e}")

def cleanup_temp_files():
    """–£–¥–∞–ª—è–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ mp3 —Ñ–∞–π–ª—ã, –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∑–∞–ø—É—Å–∫–æ–≤."""
    try:
        for f in os.listdir("."):
            if f.startswith("temp_") and f.endswith(".mp3"):
                try:
                    os.remove(f)
                    logging.info(f"üßπ –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {f}")
                except Exception as e:
                    logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {f}: {e}")
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {e}")

async def generate_audio_bytes(text, voice="ko-KR-SunHiNeural") -> bytes:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ –≤ –ø–∞–º—è—Ç—å —á–µ—Ä–µ–∑ Microsoft Edge TTS"""
    clean_text = clean_text_for_tts(text)
    if not clean_text: return None

    for i in range(3): # 3 –ø–æ–ø—ã—Ç–∫–∏ –ø—Ä–∏ –æ—à–∏–±–∫–µ —Å–µ—Ç–∏
        try:
            communicate = edge_tts.Communicate(clean_text, voice)
            audio_data = b""
            async for chunk in communicate.stream():
                if chunk["type"] == "audio":
                    audio_data += chunk["data"]
            
            if len(audio_data) < MIN_FILE_SIZE:
                logging.warning(f"‚ö†Ô∏è –ê—É–¥–∏–æ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ: {text}")
                return None
            return audio_data
        except Exception as e:
            if i == 2: logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Edge TTS: {e}")
            await asyncio.sleep(1)
    return None

async def generate_dialogue_bytes(text) -> bytes:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∏–∞–ª–æ–≥–∞ –≤ –ø–∞–º—è—Ç—å"""
    lines = text.replace('\r\n', '\n').split('\n')
    
    voice_female = "ko-KR-SunHiNeural"
    voice_male = "ko-KR-InJoonNeural"
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º SSML —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    ssml_parts = [
        '<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="ko-KR">'
    ]
    
    current_voice = voice_female
    has_content = False
    
    try:
        for line in lines:
            line = line.strip()
            if not line: continue
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–æ–ª–æ—Å–∞
            if re.match(r'^[AaÍ∞Ä]\s*:', line):
                current_voice = voice_female
                line = re.sub(r'^[AaÍ∞Ä]\s*:', '', line).strip()
            elif re.match(r'^[BbÎÇò]\s*:', line):
                current_voice = voice_male
                line = re.sub(r'^[BbÎÇò]\s*:', '', line).strip()
            
            if not line: continue
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—É–∑—É 500–º—Å –ø–µ—Ä–µ–¥ —Ä–µ–ø–ª–∏–∫–æ–π
            if has_content:
                 ssml_parts.append('<break time="500ms"/>')
                 
            # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã XML –∏ –æ–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≤ —Ç–µ–≥ –≥–æ–ª–æ—Å–∞
            # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç Hanja –ø–µ—Ä–µ–¥ –≤—Å—Ç–∞–≤–∫–æ–π –≤ SSML
            safe_line = clean_text_for_tts(line).replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
            ssml_parts.append(f'<voice name="{current_voice}">{safe_line}</voice>')
            has_content = True
            
        ssml_parts.append('</speak>')
        
        if not has_content: return None
        
        ssml_string = "".join(ssml_parts)
        
        communicate = edge_tts.Communicate(ssml_string, voice_female)
        audio_data = b""
        async for chunk in communicate.stream():
            if chunk["type"] == "audio":
                audio_data += chunk["data"]
        
        if len(audio_data) < MIN_FILE_SIZE:
             logging.warning(f"‚ö†Ô∏è –î–∏–∞–ª–æ–≥ —Å–ª–∏—à–∫–æ–º –º–∞–ª: {text[:20]}...")
             return None
        return audio_data
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–∏–∞–ª–æ–≥–∞ (SSML): {e}")
        return None

def check_integrity(bucket_name, table_name='vocabulary'):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ —Ñ–∞–π–ª–æ–≤ –∏ —Å—Å—ã–ª–æ–∫ –≤ –ë–î."""
    logging.info(f"üßπ –ó–∞–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –±–∞–∫–µ—Ç–∞ '{bucket_name}'...")
    
    # 1. –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤ –±–∞–∫–µ—Ç–µ
    storage_files = {}
    try:
        offset = 0
        while True:
            res = supabase.storage.from_(bucket_name).list(path=None, options={"limit": 100, "offset": offset})
            if not res: break
            for f in res:
                name = f.get('name') if isinstance(f, dict) else getattr(f, 'name', None)
                size = f.get('metadata', {}).get('size', 0) if isinstance(f, dict) else getattr(f, 'metadata', {}).get('size', 0)
                if name: storage_files[name] = size
            offset += 100
            if len(res) < 100: break
        logging.info(f"üìÇ –§–∞–π–ª–æ–≤ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ: {len(storage_files)}")
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤: {e}")
        return

    # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Å—ã–ª–∫–∏ –≤ –ë–î
    try:
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ (–ø–∞–≥–∏–Ω–∞—Ü–∏—è –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è –¥–ª—è –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö –ë–î)
        rows = []
        offset = 0
        while True:
            res = supabase.table(DB_TABLES.get(table_name.upper(), table_name)).select("*").range(offset, offset + 999).execute()
            if not res.data: break
            rows.extend(res.data)
            offset += 1000
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ë–î: {e}")
        return

    referenced_files = set()
    fixed_count = 0

    # –ö–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ñ–∞–π–ª—ã –≤ —ç—Ç–æ–º –±–∞–∫–µ—Ç–µ
    target_cols = ['audio_url', 'audio_male', 'example_audio'] if bucket_name == DB_BUCKETS['AUDIO'] else ['image']

    for row in rows:
        if not isinstance(row, dict): continue
        row_id = row.get('id')
        updates = {}
        for col in target_cols:
            url = row.get(col)
            if not url or not isinstance(url, str): continue
            
            filename = unquote(url.split('/')[-1].split('?')[0]) # –£–±–∏—Ä–∞–µ–º query params –∏ –¥–µ–∫–æ–¥–∏—Ä—É–µ–º

            # –ü—Ä–æ–≤–µ—Ä–∫–∞: —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –Ω–µ –ø—É—Å—Ç–æ–π (–¥–ª—è –∞—É–¥–∏–æ > 100 –±–∞–π—Ç)
            min_size = 100 if bucket_name == DB_BUCKETS['AUDIO'] else 0
            
            if filename not in storage_files or storage_files[filename] <= min_size:
                logging.warning(f"‚ö†Ô∏è –ë–∏—Ç–∞—è —Å—Å—ã–ª–∫–∞ –∏–ª–∏ –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª: id={row_id} col={col} file={filename}")
                updates[col] = None # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—Å—ã–ª–∫—É, —á—Ç–æ–±—ã —Å–∫—Ä–∏–ø—Ç –ø–µ—Ä–µ—Å–æ–∑–¥–∞–ª –µ—ë
                if col == 'image':
                    updates['image_source'] = None # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫, —á—Ç–æ–±—ã —Ä–∞–∑—Ä–µ—à–∏—Ç—å –ø–µ—Ä–µ–∑–∞–ø–∏—Å—å
            else:
                referenced_files.add(filename) # –§–∞–π–ª –≤–∞–ª–∏–¥–µ–Ω, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –µ–≥–æ –æ—Ç —É–¥–∞–ª–µ–Ω–∏—è
        
        if updates:
            try:
                supabase.table(DB_TABLES.get(table_name.upper(), table_name)).update(updates).eq('id', row_id).execute()
                fixed_count += 1
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è id={row_id}: {e}")

    logging.info(f"‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π –≤ –ë–î: {fixed_count}")

    # 3. –£–¥–∞–ª—è–µ–º —Å–∏—Ä–æ—Ç (—Ñ–∞–π–ª—ã –±–µ–∑ —Å—Å—ã–ª–æ–∫)
    orphans = [f for f in storage_files if f not in referenced_files]
    if orphans:
        logging.info(f"üóë –ù–∞–π–¥–µ–Ω–æ {len(orphans)} –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤. –£–¥–∞–ª–µ–Ω–∏–µ...")
        # –£–¥–∞–ª—è–µ–º –ø–∞—á–∫–∞–º–∏ –ø–æ 10
        for i in range(0, len(orphans), 10):
            batch = orphans[i:i+10]
            try:
                supabase.storage.from_(bucket_name).remove(batch)
                logging.info(f"   –£–¥–∞–ª–µ–Ω–æ: {batch}")
            except Exception as e:
                logging.error(f"   –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è: {e}")
    else:
        logging.info("‚ú® –õ–∏—à–Ω–∏—Ö —Ñ–∞–π–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")

def optimize_image_data(data):
    """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é Pillow"""
    try:
        img = Image.open(BytesIO(data))
        if img.mode != 'RGB':
            img = img.convert('RGB')
        output = BytesIO()
        img.save(output, format='JPEG', quality=80, optimize=True)
        return output.getvalue()
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        return data

if args.check:
    check_integrity(DB_BUCKETS['AUDIO'], DB_TABLES['VOCABULARY'])
    check_integrity(DB_BUCKETS['IMAGES'], DB_TABLES['VOCABULARY'])
    logging.info("üèÅ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ü–µ—Ä–µ—Ö–æ–¥ –∫ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—é –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")

async def upload_to_supabase(bucket, path, data, content_type):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤ Supabase"""
    loop = asyncio.get_running_loop()
    
    def _do_upload():
        for i in range(3):
            try:
                if hasattr(data, 'seek'): data.seek(0)
                return supabase.storage.from_(bucket).upload(
                    path=path, file=data, file_options={"content-type": content_type, "upsert": "true"}
                )
            except Exception as e:
                if "10035" in str(e) or "10054" in str(e): time.sleep(1); continue
                raise e

    await loop.run_in_executor(None, _do_upload)

async def handle_main_audio(session, row, word, word_hash, force_audio=False):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∞—É–¥–∏–æ (–ñ–µ–Ω—Å–∫–∏–π –≥–æ–ª–æ—Å - SunHi)"""
    if row.get('audio_url') and not force_audio: return {}
    
    audio_filename = f"{word_hash}.mp3"
    
    audio_data = await generate_audio_bytes(word, "ko-KR-SunHiNeural")
    
    if audio_data:
        if row.get('audio_url'):
            await delete_old_file(DB_BUCKETS['AUDIO'], row.get('audio_url'))
        
        await upload_to_supabase(DB_BUCKETS['AUDIO'], audio_filename, BytesIO(audio_data), "audio/mpeg")
        url = supabase.storage.from_(DB_BUCKETS['AUDIO']).get_public_url(audio_filename)
        logging.info(f"‚úÖ Audio Female: {word}")
        return {'audio_url': url}

    return {}

async def handle_male_audio(row, word, word_hash, force_audio=False):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –º—É–∂—Å–∫–æ–≥–æ –∞—É–¥–∏–æ (EdgeTTS)"""
    if row.get('audio_male') and not force_audio: return {}
    
    male_filename = f"{word_hash}_M.mp3"
    
    audio_data = await generate_audio_bytes(word, "ko-KR-InJoonNeural")
    
    if audio_data:
        if row.get('audio_male'):
            await delete_old_file(DB_BUCKETS['AUDIO'], row.get('audio_male'))
        
        await upload_to_supabase(DB_BUCKETS['AUDIO'], male_filename, BytesIO(audio_data), "audio/mpeg")
        url = supabase.storage.from_(DB_BUCKETS['AUDIO']).get_public_url(male_filename)
        logging.info(f"‚úÖ Audio Male: {word}")
        return {'audio_male': url}

    return {}

async def handle_example_audio(row, example, force_audio=False):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ –ø—Ä–∏–º–µ—Ä–∞ (Dialogue/EdgeTTS)"""
    if not example or not isinstance(example, str): return {}
    if row.get('example_audio') and not force_audio: return {}
    
    ex_hash = hashlib.md5(example.encode('utf-8')).hexdigest()
    ex_filename = f"ex_{ex_hash}.mp3"
    audio_data = None
    
    is_dialogue = re.search(r'(^|\n)[AaBbÍ∞ÄÎÇò]\s*:', example)
    if is_dialogue:
        audio_data = await generate_dialogue_bytes(example)
    else:
        audio_data = await generate_audio_bytes(example, "ko-KR-SunHiNeural")
    
    if audio_data:
        if row.get('example_audio'):
            await delete_old_file(DB_BUCKETS['AUDIO'], row.get('example_audio'))
        await upload_to_supabase(DB_BUCKETS['AUDIO'], ex_filename, BytesIO(audio_data), "audio/mpeg")
        url = supabase.storage.from_(DB_BUCKETS['AUDIO']).get_public_url(ex_filename)
        logging.info(f"‚úÖ Example: {example[:10]}...")
        return {'example_audio': url}

    return {}

async def handle_image(session, row, translation, word_hash, force_images):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ Edge Function (Auto Mode)"""
    current_image = row.get('image')
    image_source = row.get('image_source')

    if current_image:
        # –ï—Å–ª–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ –ù–ï 'pixabay' (–∑–Ω–∞—á–∏—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è) ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≤—Å–µ–≥–¥–∞
        if image_source not in ['pixabay', 'unsplash', 'pexels'] and not force_images:
            return {}
        # –ï—Å–ª–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ 'pixabay', –Ω–æ –Ω–µ –≤–∫–ª—é—á–µ–Ω force ‚Äî —Ç–æ–∂–µ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        if not force_images:
            return {}

    # 2. –ï—Å–ª–∏ –¥–æ—à–ª–∏ —Å—é–¥–∞: –ª–∏–±–æ –∫–∞—Ä—Ç–∏–Ω–∫–∏ –Ω–µ—Ç, –ª–∏–±–æ —ç—Ç–æ –∞–≤—Ç–æ-–∫–∞—Ä—Ç–∏–Ω–∫–∞ + force
    if not translation: return {}
    
    try:
        function_url = f"{SUPABASE_URL}functions/v1/regenerate-image"
        headers = {
            "Authorization": f"Bearer {SUPABASE_KEY}",
            "Content-Type": "application/json"
        }
        payload = {
            "mode": "auto",
            "id": row.get('id'),
            "word": row.get('word_kr'),
            "translation": row.get('translation')
        }
        
        async with session.post(function_url, json=payload, headers=headers, timeout=aiohttp.ClientTimeout(total=30)) as resp:
            if resp.status == 200:
                data = await resp.json()
                logging.info(f"‚úÖ Image (Edge Auto): {translation} -> {data.get('source')}")
                return {}
            else:
                if resp.status != 404:
                    text = await resp.text()
                    logging.warning(f"‚ö†Ô∏è Edge Function Error: {resp.status} - {text}")
                return {}

    except asyncio.TimeoutError:
        logging.warning(f"‚ö†Ô∏è Timeout –ø—Ä–∏ –≤—ã–∑–æ–≤–µ Edge Function –¥–ª—è {translation}")
        return {}
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ Edge Function –¥–ª—è {translation}: {e}")
        return {}

async def reset_failed_requests():
    """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –æ—à–∏–±–æ—á–Ω—ã—Ö –∑–∞—è–≤–æ–∫ –Ω–∞ 'pending' –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
    try:
        # –ü—ã—Ç–∞–µ–º—Å—è –æ–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å ERROR -> PENDING
        builder = supabase.table(DB_TABLES['WORD_REQUESTS']).update({'status': WORD_REQUEST_STATUS['PENDING']}).eq('status', WORD_REQUEST_STATUS['ERROR'])
        res = await execute_supabase_query(builder)
        
        count = len(res.data) if res and res.data else 0
        if count > 0:
            logging.info(f"‚ôªÔ∏è –ê–≤—Ç–æ-—Å–±—Ä–æ—Å: {count} –æ—à–∏–±–æ—á–Ω—ã—Ö –∑–∞—è–≤–æ–∫ –≤–æ–∑–≤—Ä–∞—â–µ–Ω–æ –≤ –æ—á–µ—Ä–µ–¥—å.")
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–≤—Ç–æ-—Å–±—Ä–æ—Å–µ –∑–∞—è–≤–æ–∫: {e}")

async def _generate_content_for_word(session, row):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è —Å–ª–æ–≤–∞ (–∞—É–¥–∏–æ, –∫–∞—Ä—Ç–∏–Ω–∫–∏)"""
    word = row.get('word_kr')
    translation = row.get('translation')
    example = row.get('example_kr')
    word_hash = hashlib.md5(word.encode('utf-8')).hexdigest()

    tasks = [
        handle_main_audio(session, row, word, word_hash, args.force_audio),
        handle_male_audio(row, word, word_hash, args.force_audio),
        handle_example_audio(row, example, args.force_audio),
        handle_image(session, row, translation, word_hash, args.force_images)
    ]
    
    results = await asyncio.gather(*tasks)
    updates = {}
    for res in results:
        if res: updates.update(res)
    return updates

def _handle_processing_error(e, word, error_counter):
    """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    err_str = str(e).lower()
    if isinstance(e, (aiohttp.ClientError, asyncio.TimeoutError)) or \
       'timeout' in err_str or 'connection' in err_str or 'network' in err_str:
        logging.warning(f"üåê –°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ '{word}': {e}")
        error_counter['network'] += 1
    else:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–ª–æ–≤–∞ '{word}': {e}")
        error_counter['other'] += 1

async def process_word(sem, session, row, error_counter):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Å–ª–æ–≤–∞ (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ)"""
    async with sem: # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
        row_id = row.get('id')
        word = row.get('word_kr')
        
        if not isinstance(row, dict) or not word or not isinstance(word, str):
            return row_id

        try:
            updates_to_make = await _generate_content_for_word(session, row)
            
            if updates_to_make:
                builder = supabase.table(DB_TABLES['VOCABULARY']).update(updates_to_make).eq("id", row_id)
                await execute_supabase_query(builder)
                return None # –£—Å–ø–µ—Ö
            else:
                return row_id
        except Exception as e:
            _handle_processing_error(e, word, error_counter)
            return row_id

async def process_word_request(request, session=None):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞—è–≤–∫–∏ –Ω–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ª–æ–≤–∞ —á–µ—Ä–µ–∑ AI"""
    req_id = request.get('id')
    word_kr = request.get('word_kr')
    user_id = request.get('user_id')
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä—É—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–º–∏–Ω–∏–º—É–º –ø–µ—Ä–µ–≤–æ–¥)
    has_manual_data = bool(request.get('translation'))

    if not word_kr:
        return

    if not has_manual_data and not GEMINI_API_KEY:
        logging.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫ {word_kr}: –Ω–µ—Ç –∫–ª—é—á–∞ Gemini –∏ –Ω–µ—Ç —Ä—É—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.")
        builder = supabase.table(DB_TABLES['WORD_REQUESTS']).update({
            'status': WORD_REQUEST_STATUS['ERROR'], 
            'my_notes': 'Server Error: Missing Gemini API Key'
        }).eq('id', req_id)
        await execute_supabase_query(builder)
        return

    logging.info(f"ü§ñ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {word_kr} (–†—É—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {has_manual_data})")

    try:
        items_to_process = []
        if has_manual_data:
            manual_item = request.copy()
            manual_item['word_kr'] = word_kr
            items_to_process.append(manual_item)
        else:
            # 1. –ó–∞–ø—Ä–æ—Å –∫ Gemini –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
            prompt = f"""You are an expert Korean language teacher for Russian speakers.
Analyze the input: '{word_kr}'.

### 1. Identification & Correction
- Detect if the input is Korean, a typo (e.g. 'gks' -> 'Ìïú'), or Romanization (e.g. 'annyeong' -> 'ÏïàÎÖï').
- Use the **corrected Korean word** for analysis.
- If the input is gibberish or not a valid Korean word, return: {{"error": "Invalid input"}}

### 2. Analysis Rules
- If the word has multiple distinct meanings (homonyms), return a JSON ARRAY of objects (max 3 most common).
- If it has a single meaning, return a single JSON object.
- **Strictly** follow the JSON structure below. Do NOT use Markdown formatting (no ```json).

### 3. JSON Structure
Each object must have:
- "word_kr": string (The corrected Korean word)
- "translation": string (Concise Russian translation, 1-3 words)
- "word_hanja": string (Hanja characters ONLY if applicable. Empty string if native Korean)
- "topic": string (One from: {', '.join(valid_topics)})
- "category": string (One from: {', '.join(valid_categories)})
- "level": string (One of: "‚òÖ‚òÖ‚òÖ" (Beginner), "‚òÖ‚òÖ‚òÜ" (Intermediate), "‚òÖ‚òÜ‚òÜ" (Advanced))
- "example_kr": string (A simple, natural Korean sentence using the word in **polite informal style (Ìï¥ÏöîÏ≤¥)**)
- "example_ru": string (Russian translation of the example)
- "synonyms": string (Comma-separated Korean synonyms **matching this specific meaning**, max 3. Empty if none)
- "antonyms": string (Comma-separated Korean antonyms **matching this specific meaning**, max 3. Empty if none)
- "collocations": string (Common word pairings, e.g. "make friends", max 3)
- "grammar_info": string (Brief usage note, conjugation tip, or Hanja meaning breakdown. E.g. "Irregular verb" or "Â≠∏(learn) Ê†°(school)")
- "type": string ("word" or "grammar")

### 4. Constraints
- Topic/Category MUST be exactly from the provided lists. If unsure, use "Other (–î—Ä—É–≥–æ–µ)".
- Examples should be suitable for the word's difficulty level.
- Output ONLY the JSON string.

Input: '{word_kr}'
"""
            
            # –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø–µ—Ä–µ–±–æ—Ä–∞ (Fallback —Å—Ç—Ä–∞—Ç–µ–≥–∏—è)
            models_to_try = ['gemini-2.5-flash', 'gemini-2.0-flash', 'gemini-flash-latest']
            text_response = None
            last_error = None

            for model_name in models_to_try:
                try:
                    # FIX: –î–æ–±–∞–≤–ª—è–µ–º —Ç–∞–π–º–∞—É—Ç, —á—Ç–æ–±—ã –≤–æ—Ä–∫–µ—Ä –Ω–µ –∑–∞–≤–∏—Å –Ω–∞ –æ–∂–∏–¥–∞–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç Google
                    response = await asyncio.wait_for(asyncio.to_thread(
                        genai.GenerativeModel(model_name).generate_content,
                        contents=prompt
                    ), timeout=30.0)
                    text_response = response.text
                    
                    if text_response:
                        logging.info(f"‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω –æ—Ç –º–æ–¥–µ–ª–∏: {model_name}")
                        break
                except Exception as e:
                    logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏ {model_name}: {e}")
                    last_error = e
            
            if not text_response:
                logging.error(f"‚ùå –í—Å–µ –º–æ–¥–µ–ª–∏ AI –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã –¥–ª—è {word_kr}. –û—à–∏–±–∫–∞: {last_error}")
                builder = supabase.table(DB_TABLES['WORD_REQUESTS']).update({'status': WORD_REQUEST_STATUS['ERROR'], 'my_notes': f'All AI models failed: {last_error}'}).eq('id', req_id)
                await execute_supabase_query(builder)
                return
            
            # –û—á–∏—Å—Ç–∫–∞ –æ—Ç markdown ```json ... ```
            if "```json" in text_response:
                text_response = text_response.split("```json")[1].split("```")[0]
            elif "```" in text_response:
                text_response = text_response.split("```")[1].split("```")[0]
                
            try:
                parsed_data = json.loads(text_response.strip())
            except json.JSONDecodeError:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –¥–ª—è {word_kr}")
                builder = supabase.table(DB_TABLES['WORD_REQUESTS']).update({'status': WORD_REQUEST_STATUS['ERROR'], 'my_notes': 'Invalid JSON'}).eq('id', req_id)
                await execute_supabase_query(builder)
                return

            if isinstance(parsed_data, dict) and parsed_data.get("error") == "Invalid input":
                logging.warning(f"‚ö†Ô∏è AI rejected input '{word_kr}': Invalid input")
                builder = supabase.table(DB_TABLES['WORD_REQUESTS']).update({
                    'status': WORD_REQUEST_STATUS['ERROR'],
                    'my_notes': 'AI: Invalid input'
                }).eq('id', req_id)
                await execute_supabase_query(builder)
                return

            if isinstance(parsed_data, list):
                items_to_process = parsed_data
            elif isinstance(parsed_data, dict):
                items_to_process = [parsed_data]
            else:
                logging.error(f"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ AI –¥–ª—è {word_kr}")
                builder = supabase.table(DB_TABLES['WORD_REQUESTS']).update({'status': WORD_REQUEST_STATUS['ERROR']}).eq('id', req_id)
                await execute_supabase_query(builder)
                return
        
        if not items_to_process:
             logging.error(f"‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ {word_kr}")
             builder = supabase.table(DB_TABLES['WORD_REQUESTS']).update({'status': WORD_REQUEST_STATUS['ERROR']}).eq('id', req_id)
             await execute_supabase_query(builder)
             return

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ (–∑–Ω–∞—á–µ–Ω–∏—è —Å–ª–æ–≤–∞)
        success_count = 0
        for data in items_to_process:
            if not data.get('word_kr'):
                continue
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ä—É—á–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ç–µ–º—ã/–∫–∞—Ç–µ–≥–æ—Ä–∏–∏, –µ—Å–ª–∏ –æ–Ω–∏ –±—ã–ª–∏ —É–∫–∞–∑–∞–Ω—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
            # –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–æ, —á—Ç–æ –ø—Ä–∏–¥—É–º–∞–ª AI
            if request.get('topic'): data['topic'] = request.get('topic')
            if request.get('category'): data['category'] = request.get('category')

            # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ vocabulary
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ —Ç–æ–ª—å–∫–æ –ø–æ —Å–ª–æ–≤—É, –Ω–æ –∏ –ø–æ –ø–µ—Ä–µ–≤–æ–¥—É, —á—Ç–æ–±—ã —Ä–∞–∑–ª–∏—á–∞—Ç—å –æ–º–æ–Ω–∏–º—ã
            builder = supabase.table(DB_TABLES['VOCABULARY']).select('id, translation').eq('word_kr', data.get('word_kr'))
            existing_rows = (await execute_supabase_query(builder)).data or []
            
            word_id = None
            
            # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –ø–µ—Ä–µ–≤–æ–¥—É (–∏–ª–∏ –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–µ–µ)
            for row in existing_rows:
                if row.get('translation') == data.get('translation'):
                    word_id = row['id']
                    success_count += 1
                    logging.info(f"‚ÑπÔ∏è –°–ª–æ–≤–æ {data.get('word_kr')} ({data.get('translation')}) —É–∂–µ –µ—Å—Ç—å –≤ –±–∞–∑–µ.")
                    break
            
            if not word_id:
                # 3. –í—Å—Ç–∞–≤–∫–∞ –≤ vocabulary
                allowed_keys = {
                    'word_kr', 'translation', 'word_hanja', 'topic', 'category', 
                    'level', 'type', 'example_kr', 'example_ru', 'synonyms', 'antonyms',
                    'collocations', 'grammar_info',
                    'user_id' # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–µ –≤–ª–∞–¥–µ–ª—å—Ü–∞
                }
                # –ï—Å–ª–∏ –µ—Å—Ç—å user_id –≤ –∑–∞–ø—Ä–æ—Å–µ, –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ –≤ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏
                if user_id: data['user_id'] = user_id
                
                clean_data = {k: v for k, v in data.items() if k in allowed_keys}
                
                # –ï—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∏ grammar_info –Ω–µ—Ç –≤ –±–∞–∑–µ, —É–¥–∞–ª—è–µ–º –µ—ë –∏–∑ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –≤—Å—Ç–∞–≤–∫–æ–π
                if not HAS_GRAMMAR_INFO and 'grammar_info' in clean_data:
                    del clean_data['grammar_info']
                
                try:
                    builder = supabase.table(DB_TABLES['VOCABULARY']).insert(clean_data)
                    insert_data = (await execute_supabase_query(builder)).data
                except Exception as e:
                    logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—Å—Ç–∞–≤–∫–∏ –≤ –ë–î: {e}")
                    insert_data = None
                
                if insert_data and isinstance(insert_data, list) and len(insert_data) > 0:
                    word_id = insert_data[0]['id']
                    success_count += 1
                    logging.info(f"‚úÖ –°–ª–æ–≤–æ {data.get('word_kr')} ({data.get('translation')}) –¥–æ–±–∞–≤–ª–µ–Ω–æ.")
                    
                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –º–µ–¥–∏–∞ –¥–ª—è –Ω–æ–≤–æ–≥–æ —Å–ª–æ–≤–∞ —Å—Ä–∞–∑—É
                    if session:
                        updates = await _generate_content_for_word(session, insert_data[0])
                    else:
                        async with aiohttp.ClientSession() as local_session:
                            updates = await _generate_content_for_word(local_session, insert_data[0])
                    
                    if updates:
                        update_builder = supabase.table(DB_TABLES['VOCABULARY']).update(updates).eq("id", word_id)
                        await execute_supabase_query(update_builder)
                else:
                    logging.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –≤—Å—Ç–∞–≤–∏—Ç—å —Å–ª–æ–≤–æ '{data.get('word_kr')}'. –û—Ç–≤–µ—Ç –ë–î –ø—É—Å—Ç (–≤–æ–∑–º–æ–∂–Ω–æ, –æ—à–∏–±–∫–∞ –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞ RLS).")

            # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –î–æ–±–∞–≤–∏—Ç—å —Å–ª–æ–≤–æ –≤ "–ò–∑—É—á–∞–µ–º—ã–µ" –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∫–æ—Ç–æ—Ä—ã–π –µ–≥–æ –∑–∞–ø—Ä–æ—Å–∏–ª
            if word_id and user_id:
                 try:
                     builder = supabase.table(DB_TABLES['USER_PROGRESS']).upsert({'user_id': user_id, 'word_id': word_id, 'is_learned': False})
                     await execute_supabase_query(builder)
                 except Exception as e:
                     logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –≤ –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {e}")

            # 5. –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ —Å–ø–∏—Å–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω target_list_id)
            target_list_id = request.get('target_list_id')
            if word_id and target_list_id:
                try:
                    builder = supabase.table(DB_TABLES['LIST_ITEMS']).upsert({'list_id': target_list_id, 'word_id': word_id})
                    await execute_supabase_query(builder)
                    logging.info(f"‚úÖ –°–ª–æ–≤–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ —Å–ø–∏—Å–æ–∫ {target_list_id}")
                except Exception as e:
                    logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ —Å–ø–∏—Å–æ–∫: {e}")

        # 4. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞—è–≤–∫–∏ (–ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—Å–µ—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤)
        final_status = WORD_REQUEST_STATUS['PROCESSED']
        notes = None
        
        if success_count == 0:
             final_status = WORD_REQUEST_STATUS['ERROR']
             notes = "System: Failed to insert/find word in DB (RLS or Unknown Error)"
        
        update_payload = {'status': final_status}
        if notes: update_payload['my_notes'] = notes
        
        builder = supabase.table(DB_TABLES['WORD_REQUESTS']).update(update_payload).eq('id', req_id)
        await execute_supabase_query(builder)

    except asyncio.TimeoutError:
        logging.error(f"‚ùå Timeout AI –¥–ª—è {word_kr}")
        builder = supabase.table(DB_TABLES['WORD_REQUESTS']).update({'status': WORD_REQUEST_STATUS['ERROR'], 'my_notes': 'AI Timeout'}).eq('id', req_id)
        await execute_supabase_query(builder)

    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ AI –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è {word_kr}: {e}")
        builder = supabase.table(DB_TABLES['WORD_REQUESTS']).update({'status': WORD_REQUEST_STATUS['ERROR']}).eq('id', req_id)
        await execute_supabase_query(builder)

async def handle_quote_audio(row, force_audio=False):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ –¥–ª—è —Ü–∏—Ç–∞—Ç—ã (EdgeTTS)"""
    if row.get('audio_url') and not force_audio: return {}
    
    text = row.get('quote_kr')
    if not text: return {}
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ö–µ—à –æ—Ç —Ç–µ–∫—Å—Ç–∞ —Ü–∏—Ç–∞—Ç—ã –¥–ª—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
    quote_hash = hashlib.md5(text.encode('utf-8')).hexdigest()
    filename = f"quote_{quote_hash}.mp3"
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ –≥–æ–ª–æ—Å, —á—Ç–æ –∏ –¥–ª—è —Å–ª–æ–≤ (SunHi)
    audio_data = await generate_audio_bytes(text, "ko-KR-SunHiNeural")
    
    if audio_data:
        if row.get('audio_url'):
            await delete_old_file(DB_BUCKETS['AUDIO'], row.get('audio_url'))
        await upload_to_supabase(DB_BUCKETS['AUDIO'], filename, BytesIO(audio_data), "audio/mpeg")
        url = supabase.storage.from_(DB_BUCKETS['AUDIO']).get_public_url(filename)
        logging.info(f"‚úÖ Quote Audio: {text[:15]}...")
        return {'audio_url': url}

    return {}

async def process_quote(sem, session, row):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–π —Ü–∏—Ç–∞—Ç—ã"""
    async with sem:
        row_id = row.get('id')
        try:
            updates = await handle_quote_audio(row, args.force_audio or args.force_quotes)
            if updates:
                builder = supabase.table(DB_TABLES['QUOTES']).update(updates).eq('id', row_id)
                await execute_supabase_query(builder)
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Ü–∏—Ç–∞—Ç—ã {row_id}: {e}")

async def measure_network_quality():
    """–ò–∑–º–µ—Ä—è–µ—Ç –∑–∞–¥–µ—Ä–∂–∫—É —Å–µ—Ç–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤."""
    logging.info("üì° –ê–Ω–∞–ª–∏–∑ —Å–∫–æ—Ä–æ—Å—Ç–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è...")
    test_url = "https://www.google.com"
    start = time.time()
    try:
        async with aiohttp.ClientSession() as session:
            # –î–µ–ª–∞–µ–º 3 –ª–µ–≥–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è
            for _ in range(3):
                async with session.get(test_url, timeout=aiohttp.ClientTimeout(total=5)) as response:
                    await response.read()
        
        duration = time.time() - start
        avg_latency = duration / 3
        
        logging.info(f"‚è± –°—Ä–µ–¥–Ω–∏–π –æ—Ç–∫–ª–∏–∫: {avg_latency:.3f} —Å–µ–∫.")
        
        if avg_latency < 0.15: return 25 # –û—Ç–ª–∏—á–Ω—ã–π –∏–Ω—Ç–µ—Ä–Ω–µ—Ç
        if avg_latency < 0.30: return 15 # –•–æ—Ä–æ—à–∏–π
        if avg_latency < 0.60: return 8  # –°—Ä–µ–¥–Ω–∏–π
        if avg_latency < 1.00: return 4  # –ú–µ–¥–ª–µ–Ω–Ω—ã–π
        return 2 # –û—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω—ã–π
        
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–º–µ—Ä–∏—Ç—å —Å–∫–æ—Ä–æ—Å—Ç—å ({e}). –ò—Å–ø–æ–ª—å–∑—É—é –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (5).")
        return 5

async def check_internet_connection():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ –ø–µ—Ä–µ–¥ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º –∫ Realtime"""
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get("https://www.google.com", timeout=2) as resp:
                return resp.status == 200
    except:
        return False

async def realtime_loop(trigger_event: asyncio.Event):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Ü–∏–∫–ª –¥–ª—è Realtime –ø–æ–¥–ø–∏—Å–∫–∏ (—Ç—Ä–µ–±—É–µ—Ç async client)"""

    def on_insert_callback(payload):
        logging.info("üîî Realtime: –ü–æ–ª—É—á–µ–Ω–∞ –Ω–æ–≤–∞—è –∑–∞—è–≤–∫–∞!")
        trigger_event.set()
        
    retry_delay = 5

    while True:
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–µ—Ç–∏ –ø–µ—Ä–µ–¥ –ø–æ–ø—ã—Ç–∫–æ–π –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è, —á—Ç–æ–±—ã –Ω–µ –ª–æ–≤–∏—Ç—å getaddrinfo failed
            if not await check_internet_connection():
                logging.warning(f"üåê –ù–µ—Ç –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞. –û–∂–∏–¥–∞–Ω–∏–µ {retry_delay} —Å–µ–∫ –ø–µ—Ä–µ–¥ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º –∫ Realtime...")
                await asyncio.sleep(retry_delay)
                retry_delay = min(retry_delay * 1.5, 60)
                continue

            logging.info("üü¢ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Async Realtime –∫–ª–∏–µ–Ω—Ç–∞...")
            # –°–æ–∑–¥–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–π –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è Realtime
            async_client = await create_async_client(SUPABASE_URL, SUPABASE_KEY)

            channel = async_client.channel('worker-db-changes')
            
            channel.on_postgres_changes(
                event="INSERT",
                schema="public",
                table="word_requests",
                callback=on_insert_callback
            )
            
            logging.info("üü¢ Realtime Listener: –ü–æ–¥–ø–∏—Å–∫–∞...")
            await channel.subscribe()
            logging.info("üü¢ Realtime Listener: –ü–æ–¥–ø–∏—Å–∫–∞ –∞–∫—Ç–∏–≤–Ω–∞.")
            
            # –°–±—Ä–æ—Å –∑–∞–¥–µ—Ä–∂–∫–∏ –ø—Ä–∏ —É—Å–ø–µ—à–Ω–æ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏
            retry_delay = 5
            
            # FIX: –í–º–µ—Å—Ç–æ –≤–µ—á–Ω–æ–≥–æ –æ–∂–∏–¥–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ü–∏–∫–ª —Å —Ç–∞–π–º–∞—É—Ç–æ–º (Watchdog)
            # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∫–∞–∂–¥—ã–π —á–∞—Å, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å "–º–æ–ª—á–∞–ª–∏–≤—ã—Ö" –∑–∞–≤–∏—Å–∞–Ω–∏–π —Å–æ–∫–µ—Ç–∞
            for _ in range(60): # 60 –º–∏–Ω—É—Ç
                await asyncio.sleep(60)
            
            logging.info("‚ôªÔ∏è –ü–ª–∞–Ω–æ–≤—ã–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ Realtime —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è (TTL)...")
            await channel.unsubscribe()
                
        except AttributeError as e:
            if "has no attribute" in str(e):
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–µ—Ä—Å–∏–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ Realtime ({e}). –ü–æ–ø—Ä–æ–±—É–π—Ç–µ: pip install --upgrade supabase")
                logging.warning("‚ö†Ô∏è –ü–µ—Ä–µ—Ö–æ–¥ –≤ —Ä–µ–∂–∏–º Polling (–æ–ø—Ä–æ—Å —Ä–∞–∑ –≤ 30 —Å–µ–∫).")
                return 
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Realtime: {e}. –†–µ–∫–æ–Ω–Ω–µ–∫—Ç —á–µ—Ä–µ–∑ {retry_delay} —Å–µ–∫...")
            await asyncio.sleep(retry_delay)
            retry_delay = min(retry_delay * 1.5, 60)

async def user_requests_loop(trigger_event):
    """–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π —Ü–∏–∫–ª –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞—è–≤–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
    logging.info("üëÄ –ó–∞–ø—É—â–µ–Ω –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∑–∞—è–≤–æ–∫ (–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π –ø–æ—Ç–æ–∫)...")
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Backoff (—É–º–Ω–æ–≥–æ –æ–∂–∏–¥–∞–Ω–∏—è)
    min_sleep = 2
    max_sleep = 30
    current_sleep = min_sleep

    while True:
        try:
            # –í—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞—è–≤–∫–∏
            builder = supabase.table(DB_TABLES['WORD_REQUESTS']).select("*").eq('status', WORD_REQUEST_STATUS['PENDING']).limit(5)
            reqs = await execute_supabase_query(builder)
            if reqs and reqs.data:
                logging.info(f"‚ö° –ù–∞–π–¥–µ–Ω–æ {len(reqs.data)} –Ω–æ–≤—ã—Ö –∑–∞—è–≤–æ–∫ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.")
                async with aiohttp.ClientSession() as session:
                    for req in reqs.data:
                        await process_word_request(req, session=session)
                # –ï—Å–ª–∏ –±—ã–ª–∏ –∑–∞–¥–∞—á–∏, —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Ç–∞–π–º–µ—Ä –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–Ω–æ–≤–∞ –±—ã—Å—Ç—Ä–æ
                current_sleep = min_sleep
                await asyncio.sleep(0.1)
            else:
                # –ñ–¥–µ–º —Å–æ–±—ã—Ç–∏—è –æ—Ç Realtime –ò–õ–ò –∏—Å—Ç–µ—á–µ–Ω–∏—è —Ç–∞–π–º–µ—Ä–∞ (Backoff)
                try:
                    await asyncio.wait_for(trigger_event.wait(), timeout=current_sleep)
                    trigger_event.clear() # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ–±—ã—Ç–∏–µ
                    logging.info("‚ö° –í–æ—Ä–∫–µ—Ä —Ä–∞–∑–±—É–∂–µ–Ω —Å–æ–±—ã—Ç–∏–µ–º Realtime!")
                    current_sleep = min_sleep # –°—Ä–∞–∑—É —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ–Ω –¥–ª—è –±—ã—Å—Ç—Ä–æ–π —Ä–µ–∞–∫—Ü–∏–∏
                except asyncio.TimeoutError:
                    # –ï—Å–ª–∏ —Å–æ–±—ã—Ç–∏–µ –Ω–µ –ø—Ä–∏—à–ª–æ –∑–∞ –≤—Ä–µ–º—è current_sleep, —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤—Ä–µ–º—è —Å–Ω–∞
                    current_sleep = min(current_sleep * 1.5, max_sleep)
                    
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ –∑–∞—è–≤–æ–∫: {e}")
            await asyncio.sleep(5)

async def background_tasks_loop(initial_concurrency):
    """–§–æ–Ω–æ–≤—ã–π —Ü–∏–∫–ª –¥–ª—è –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (—Ü–∏—Ç–∞—Ç—ã, –ø—Ä–æ–ø—É—Å–∫–∏)"""
    concurrency = initial_concurrency
    logging.info(f"üõ† –ó–∞–ø—É—â–µ–Ω—ã —Ñ–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ (–ù–∞—á–∞–ª—å–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤: {concurrency})...")
    
    last_reset_time = 0

    # –õ–æ–∫–∞–ª—å–Ω—ã–π –∫—ç—à –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º—ã—Ö ID (—á—Ç–æ–±—ã –Ω–µ –¥–æ–ª–±–∏—Ç—å –æ–¥–Ω–∏ –∏ —Ç–µ –∂–µ –æ—à–∏–±–∫–∏)
    ignore_ids = set()

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Backoff
    min_sleep = 5
    max_sleep = 120 # –î–æ 2 –º–∏–Ω—É—Ç –ø—Ä–æ—Å—Ç–æ—è, –µ—Å–ª–∏ –Ω–µ—Ç –∑–∞–¥–∞—á
    current_sleep = min_sleep

    while True:
        try:
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–±—Ä–æ—Å –æ—à–∏–±–æ–∫ –∫–∞–∂–¥—ã–µ 10 –º–∏–Ω—É—Ç (600 —Å–µ–∫)
            if time.time() - last_reset_time > 600:
                await reset_failed_requests()
                last_reset_time = time.time()

            cleanup_temp_files()
            
            # 0.5. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ü–∏—Ç–∞—Ç (Quotes)
            try:
                q_query = supabase.table(DB_TABLES['QUOTES']).select("*")
                if not (args.force_audio or args.force_quotes):
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ, —É –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –∞—É–¥–∏–æ (NULL –∏–ª–∏ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞)
                    q_query = q_query.or_("audio_url.is.null,audio_url.eq.")
                
                # FIX: –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç —Ü–∏—Ç–∞—Ç –∑–∞ —Ä–∞–∑, —á—Ç–æ–±—ã —á–∞—â–µ –ø—Ä–æ–≤–µ—Ä—è—Ç—å –∑–∞—è–≤–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
                q_query = q_query.limit(5)
                q_res = await execute_supabase_query(q_query)
                quotes = q_res.data if q_res else []
                
                if quotes:
                    logging.info(f"üìú –ù–∞–π–¥–µ–Ω–æ {len(quotes)} —Ü–∏—Ç–∞—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏.")
                    q_sem = asyncio.Semaphore(concurrency)
                    async with aiohttp.ClientSession() as session:
                        await asyncio.gather(*[process_quote(q_sem, session, r) for r in quotes])
            except Exception as e:
                logging.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫ —Ü–∏—Ç–∞—Ç (–≤–æ–∑–º–æ–∂–Ω–æ –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ audio_url): {e}")

            # –ó–∞–ø—Ä–æ—Å –∫ –ë–î (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π, –Ω–æ –±—ã—Å—Ç—Ä—ã–π)
            try:
                # –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω —Ä–µ–∂–∏–º —Ç–æ–ª—å–∫–æ –¥–ª—è —Ü–∏—Ç–∞—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–æ–≤–∞
                if args.force_quotes and not (args.force_images or args.force_audio):
                    words = []
                else:
                    if args.force_images or args.force_audio:
                        query = supabase.table(DB_TABLES['VOCABULARY']).select("*")
                    else:
                        # –ë–µ—Ä–µ–º –±–æ–ª—å—à–µ —Å–ª–æ–≤ –∑–∞ —Ä–∞–∑ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
                        query = supabase.table(DB_TABLES['VOCABULARY']).select("*").or_("audio_url.is.null,audio_male.is.null,image.is.null,example_audio.is.null").limit(200)
                    
                    if args.topic:
                        query = query.ilike("topic", f"%{args.topic}%")

                    if args.word:
                        query = query.eq("word_kr", args.word)

                    response = await execute_supabase_query(query)
                    words = response.data if response else []
                    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –ø—ã—Ç–∞–ª–∏—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏ –Ω–µ —Å–º–æ–≥–ª–∏
                    words = [w for w in words if isinstance(w, dict) and w.get('id') not in ignore_ids]
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ë–î: {e}")
                words = []

            if not words:
                if args.force_quotes:
                    logging.info("üèÅ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ü–∏—Ç–∞—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
                    break
                elif not args.force_images and not args.force_audio:
                    if current_sleep < max_sleep:
                        logging.info(f"üí§ –ù–µ—Ç –Ω–æ–≤—ã—Ö —Å–ª–æ–≤. –°–ø–ª—é {current_sleep:.1f} —Å–µ–∫...")
                    await asyncio.sleep(current_sleep)
                    current_sleep = min(current_sleep * 1.5, max_sleep)
                else:
                    logging.info("üèÅ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ (force mode).")
                    break
                continue
            
            # –ï—Å–ª–∏ –∑–∞–¥–∞—á–∏ –Ω–∞–π–¥–µ–Ω—ã - —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Ç–∞–π–º–µ—Ä —Å–Ω–∞
            current_sleep = min_sleep

            logging.info(f"üî• –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {len(words)} —Å–ª–æ–≤... (–ü–æ—Ç–æ–∫–æ–≤: {concurrency})")
            
            sem = asyncio.Semaphore(concurrency)
            error_counter = {'network': 0, 'other': 0}

            async with aiohttp.ClientSession() as session:
                tasks = [process_word(sem, session, row, error_counter) for row in words]
                results = await asyncio.gather(*tasks)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ ID –≤ —Å–ø–∏—Å–æ–∫ –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è
                for res in results:
                    if res: ignore_ids.add(res)
                
                await asyncio.sleep(0.1) # Yield to event loop to prevent socket starvation on Windows
            
            # --- –õ–æ–≥–∏–∫–∞ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ—Å—Ç–∏ ---
            batch_size = len(words)
            if batch_size > 0:
                network_error_rate = (error_counter['network'] / batch_size) * 100
                
                # –°–Ω–∏–∂–∞–µ–º, –µ—Å–ª–∏ >15% –∑–∞–¥–∞—á –≤ –ø–∞—á–∫–µ —É–ø–∞–ª–∏ —Å —Å–µ—Ç–µ–≤–æ–π –æ—à–∏–±–∫–æ–π
                if network_error_rate > 15.0:
                    new_concurrency = max(1, int(concurrency * 0.7)) # –£–º–µ–Ω—å—à–∞–µ–º –Ω–∞ 30%
                    if new_concurrency < concurrency:
                        logging.warning(f"üìâ –í—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å —Å–µ—Ç–µ–≤—ã—Ö –æ—à–∏–±–æ–∫ ({network_error_rate:.1f}%). –°–Ω–∏–∂–∞—é –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ —Å {concurrency} –¥–æ {new_concurrency}.")
                        concurrency = new_concurrency
                # –ü–æ–≤—ã—à–∞–µ–º, –µ—Å–ª–∏ –Ω–µ –±—ã–ª–æ –æ—à–∏–±–æ–∫ –∏ –º—ã –Ω–µ –Ω–∞ –º–∞–∫—Å–∏–º—É–º–µ
                elif error_counter['network'] == 0 and concurrency < 25:
                    new_concurrency = min(25, concurrency + 1) # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –Ω–∞ 1
                    if new_concurrency > concurrency:
                        logging.info(f"üìà –°–µ—Ç—å —Å—Ç–∞–±–∏–ª—å–Ω–∞. –£–≤–µ–ª–∏—á–∏–≤–∞—é –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ –¥–æ {new_concurrency}.")
                        concurrency = new_concurrency

            logging.info(f"‚ú® –ü–∞—á–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞. –ü—Ä–æ–±–ª–µ–º–Ω—ã—Ö –≤ —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏: {len(ignore_ids)}")

        except Exception as main_e:
            logging.error(f"üî• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —Ü–∏–∫–ª–∞: {main_e}")
            await asyncio.sleep(60)

def check_schema_health():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –≤ –∫–ª—é—á–µ–≤—ã—Ö —Ç–∞–±–ª–∏—Ü–∞—Ö."""
    global HAS_GRAMMAR_INFO
    logging.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ö–µ–º—ã –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
    
    schemas_to_check = {
        DB_TABLES['VOCABULARY']: [
            'id', 'word_kr', 'translation', 'image', 'image_source', 
            'audio_url', 'audio_male', 'example_audio', 'type',
            'grammar_info' # –î–æ–±–∞–≤–ª–µ–Ω–æ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        ],
        DB_TABLES['WORD_REQUESTS']: [
            'id', 'word_kr', 'status', 'my_notes', 'target_list_id', 'user_id', 'translation'
        ],
        DB_TABLES['QUOTES']: [
            'id', 'quote_kr', 'audio_url'
        ]
    }
    
    all_ok = True
    for table, columns in schemas_to_check.items():
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤, —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ —Ä–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
            _execute_with_retry(supabase.table(table).select(",".join(columns)).limit(1))
            logging.info(f"‚úÖ –°—Ö–µ–º–∞ —Ç–∞–±–ª–∏—Ü—ã '{table}' –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞.")
        except Exception as e:
            all_ok = False
            err_msg = str(e)
            match = re.search(r"Could not find the '([^']+)' column", err_msg)
            if match:
                missing = match.group(1)
                if missing == 'grammar_info':
                    HAS_GRAMMAR_INFO = False
                    logging.warning(f"‚ö†Ô∏è –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –í —Ç–∞–±–ª–∏—Ü–µ '{table}' –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ '{missing}'. –î–∞–Ω–Ω—ã–µ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏ –Ω–µ –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω—è—Ç—å—Å—è.")
                    all_ok = True # –ù–µ —Å—á–∏—Ç–∞–µ–º —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –æ—à–∏–±–∫–æ–π
                else:
                    logging.error(f"üö® –û–®–ò–ë–ö–ê –°–•–ï–ú–´: –í —Ç–∞–±–ª–∏—Ü–µ '{table}' –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ '{missing}'")
            else:
                logging.error(f"üö® –û–®–ò–ë–ö–ê –°–•–ï–ú–´: –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–∞–±–ª–∏—Ü—É '{table}': {e}")
    
    if not all_ok:
        logging.error(f"‚ùå –í–æ—Ä–∫–µ—Ä –Ω–µ —Å–º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–∏–º–µ–Ω–∏—Ç–µ SQL-–º–∏–≥—Ä–∞—Ü–∏–∏.")
    
    return all_ok

def validate_gemini_key():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –∫–ª—é—á–∞ Gemini API."""
    if not GEMINI_API_KEY:
        return
    
    logging.info("ü§ñ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–∞ Gemini API...")
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        model.generate_content("Test")
        logging.info("‚úÖ –ö–ª—é—á Gemini API –≤–∞–ª–∏–¥–µ–Ω.")
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–ª—é—á–∞ Gemini API: {e}")

async def main_loop():
    logging.info("üöÄ –í–æ—Ä–∫–µ—Ä –∑–∞–ø—É—â–µ–Ω (Parallel Mode).")
    
    concurrency = args.concurrency
    if concurrency == 0:
        concurrency = await measure_network_quality()
        logging.info(f"‚ö° –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è —Ñ–æ–Ω–∞: {concurrency}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ö–µ–º—ã –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º
    if not check_schema_health():
        sys.exit(1)
        
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–∞ AI
    validate_gemini_key()
    
    # –°–±—Ä–æ—Å –æ—à–∏–±–æ–∫ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
    await reset_failed_requests()
    
    # –°–æ–±—ã—Ç–∏–µ –¥–ª—è –ø—Ä–æ–±—É–∂–¥–µ–Ω–∏—è –≤–æ—Ä–∫–µ—Ä–∞
    request_trigger = asyncio.Event()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±–∞ —Ü–∏–∫–ª–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    await asyncio.gather(
        user_requests_loop(request_trigger),
        background_tasks_loop(concurrency),
        realtime_loop(request_trigger)
    )

if __name__ == "__main__":
    try:
        # FIX: –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π SelectorEventLoop, —Ç–∞–∫ –∫–∞–∫ –æ–Ω –≤—ã–∑—ã–≤–∞–µ—Ç WinError 10035 –ø—Ä–∏ –Ω–∞–≥—Ä—É–∑–∫–µ.
        # ProactorEventLoop (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤ Python 3.8+) —Ä–∞–±–æ—Ç–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ —Å SSL/Sockets –Ω–∞ Windows.
        # if sys.platform == 'win32':
        #     asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
            
        asyncio.run(main_loop())
    except KeyboardInterrupt:
        logging.info("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤–æ—Ä–∫–µ—Ä–∞.")
