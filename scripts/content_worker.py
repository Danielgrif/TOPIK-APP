# –ü–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∫–æ–º–∞–Ω–¥–æ–π:
# pip install supabase python-dotenv requests idna edge-tts pillow google-genai

import os
import re
import sys
import time
import hashlib
import logging
import asyncio
import argparse
from http.server import BaseHTTPRequestHandler, HTTPServer
from urllib.parse import urlparse, parse_qs, quote, unquote
from io import BytesIO
import json

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤ —Ñ–∞–π–ª log.txt
logging.basicConfig(
    handlers=[
        logging.FileHandler('log.txt', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ],
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º –ø–∞–∫–µ—Ç–∞–º (–Ω–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ Python –∏—Ö –Ω–µ –≤–∏–¥–∏—Ç)
import site
try:
    sys.path.append(site.getusersitepackages())
except AttributeError: pass

try:
    import requests
    import aiohttp
    from supabase import create_client
    from dotenv import load_dotenv
    import edge_tts # type: ignore
    from PIL import Image
    from google import generativeai as genai
except ImportError as e:
    logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫: {e}")
    logging.error("–í–µ—Ä–æ—è—Ç–Ω–æ, —Ñ–∞–π–ª—ã –±–∏–±–ª–∏–æ—Ç–µ–∫ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω—ã. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤—ã–ø–æ–ª–Ω–∏—Ç—å —ç—Ç—É –∫–æ–º–∞–Ω–¥—É –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:")
    logging.error(f'"{sys.executable}" -m pip install --force-reinstall requests idna urllib3 chardet certifi aiohttp edge-tts supabase pillow google-genai')
    sys.exit(1)

# –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å .env (—Å—Ç–∞–Ω–¥–∞—Ä—Ç) –∏–ª–∏ env (–µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–∞–∑–≤–∞–Ω –±–µ–∑ —Ç–æ—á–∫–∏)
# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å–∫—Ä–∏–ø—Ç–∞, —á—Ç–æ–±—ã —Ç–æ—á–Ω–æ –Ω–∞–π—Ç–∏ .env
script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(script_dir)
load_dotenv(os.path.join(project_root, ".env"))

if not os.getenv("SUPABASE_URL"):
    load_dotenv(os.path.join(project_root, "env"))

# 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∏
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_KEY") # –ù—É–∂–µ–Ω –∫–ª—é—á —Å –ø—Ä–∞–≤–∞–º–∏ –∑–∞–ø–∏—Å–∏!
PIXABAY_API_KEY = os.getenv("PIXABAY_API_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
BUCKET_NAME = "audio-files"
IMAGE_BUCKET_NAME = "image-files"
MIN_FILE_SIZE = 500 # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –≤ –±–∞–π—Ç–∞—Ö (–∏—Å–∫–ª—é—á–∞–µ—Ç –ø—É—Å—Ç—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏)

# –û—á–∏—Å—Ç–∫–∞ –∫–ª—é—á–µ–π –æ—Ç –∫–∞–≤—ã—á–µ–∫, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å (—á–∞—Å—Ç–∞—è –ø—Ä–æ–±–ª–µ–º–∞ .env)
if SUPABASE_URL: SUPABASE_URL = SUPABASE_URL.replace('"', '').replace("'", "")
if SUPABASE_KEY: SUPABASE_KEY = SUPABASE_KEY.replace('"', '').replace("'", "")
if PIXABAY_API_KEY: PIXABAY_API_KEY = PIXABAY_API_KEY.replace('"', '').replace("'", "")
if GEMINI_API_KEY: GEMINI_API_KEY = GEMINI_API_KEY.replace('"', '').replace("'", "")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–µ—Ñ–æ–ª—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
if GEMINI_API_KEY == "–≤–∞—à_–∫–ª—é—á_–∑–¥–µ—Å—å":
    GEMINI_API_KEY = None

if not SUPABASE_URL or not SUPABASE_KEY:
    logging.error("‚ùå –û–®–ò–ë–ö–ê: –ù–µ –Ω–∞–π–¥–µ–Ω—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è SUPABASE_URL –∏–ª–∏ SUPABASE_SERVICE_KEY.")
    logging.error("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª .env —Å–æ–∑–¥–∞–Ω –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç —ç—Ç–∏ –∫–ª—é—á–∏.")
    sys.exit(1)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
parser = argparse.ArgumentParser(description="–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è TOPIK APP")
parser.add_argument("--topic", type=str, help="–û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ —Å–ª–æ–≤–∞ –∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ç–µ–º—ã (—Ñ–∏–ª—å—Ç—Ä –ø–æ –∫–æ–ª–æ–Ω–∫–µ 'topic')")
parser.add_argument("--force-images", action="store_true", help="–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å —Å—Ç–∞—Ä—ã–µ)")
parser.add_argument("--force-audio", action="store_true", help="–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å –∞—É–¥–∏–æ (–ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å —Å—Ç–∞—Ä—ã–µ)")
parser.add_argument("--check", action="store_true", help="–ó–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ —Ñ–∞–π–ª–æ–≤ –∏ —Å—Å—ã–ª–æ–∫ (—É–¥–∞–ª–µ–Ω–∏–µ –±–∏—Ç—ã—Ö)")
parser.add_argument("--concurrency", type=int, default=0, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤ (0 = –∞–≤—Ç–æ-–ø–æ–¥–±–æ—Ä, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0)")
args = parser.parse_args()

# –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è "Storage endpoint URL should have a trailing slash"
if not SUPABASE_URL.endswith("/"):
    SUPABASE_URL += "/"

# –ü–∞—Ç—á –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—à–∏–±–∫–∏ "Storage endpoint URL should have a trailing slash"
try:
    StorageClient = None
    # –ü—Ä–æ–±—É–µ–º –ø—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ –≤–µ—Ä—Å–∏–π supabase-py
    try:
        from storage3.utils import StorageClient # type: ignore
    except ImportError:
        try:
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø—É—Ç—å –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π
            from storage3.client import StorageClient # type: ignore
        except ImportError:
            try:
                # –ï—â–µ –æ–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –≤–µ—Ä—Å–∏–π
                from storage3 import StorageClient # type: ignore
            except ImportError:
                pass

    if StorageClient is not None:
        _original_init = StorageClient.__init__
        def _patched_init(self, url, headers, *args, **kwargs):
            if url and not url.endswith("/"):
                url += "/"
            _original_init(self, url, headers, *args, **kwargs)
        StorageClient.__init__ = _patched_init
        logging.info("‚úÖ –ü–∞—Ç—á –¥–ª—è StorageClient —É—Å–ø–µ—à–Ω–æ –ø—Ä–∏–º–µ–Ω–µ–Ω.")
    else:
        logging.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ StorageClient. –ü–∞—Ç—á –ø—Ä–æ–ø—É—â–µ–Ω (–≤–æ–∑–º–æ–∂–Ω–æ, –æ–Ω –Ω–µ –Ω—É–∂–µ–Ω –≤ —ç—Ç–æ–π –≤–µ—Ä—Å–∏–∏).")
except Exception as e:
    logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–º–µ–Ω–∏—Ç—å –ø–∞—Ç—á –¥–ª—è StorageClient: {e}")

try:
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
except Exception as e:
    logging.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Supabase: {e}")
    logging.error("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ URL –∏ KEY –≤ —Ñ–∞–π–ª–µ .env")
    sys.exit(1)

# 1.1 –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –±–∞–∫–µ—Ç–∞ (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞)
try:
    buckets = supabase.storage.list_buckets()
    if not any(b.name == BUCKET_NAME for b in buckets):
        logging.info(f"üì¶ –ë–∞–∫–µ—Ç '{BUCKET_NAME}' –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–æ–∑–¥–∞—é –Ω–æ–≤—ã–π –ø—É–±–ª–∏—á–Ω—ã–π –±–∞–∫–µ—Ç...")
        supabase.storage.create_bucket(BUCKET_NAME, options={"public": True})
        logging.info(f"‚úÖ –ë–∞–∫–µ—Ç '{BUCKET_NAME}' —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω.")
    else:
        logging.info(f"‚ÑπÔ∏è –ë–∞–∫–µ—Ç '{BUCKET_NAME}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.")
except Exception as e:
    # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫—É, –µ—Å–ª–∏ –±–∞–∫–µ—Ç —É–∂–µ –µ—Å—Ç—å, –Ω–æ API –≤–µ—Ä–Ω—É–ª –æ—à–∏–±–∫—É –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞
    logging.warning(f"‚ö†Ô∏è –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–∫–µ—Ç–∞: {e}")

# 1.2 –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –±–∞–∫–µ—Ç–∞ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
try:
    buckets = supabase.storage.list_buckets()
    if not any(b.name == IMAGE_BUCKET_NAME for b in buckets):
        logging.info(f"üì¶ –ë–∞–∫–µ—Ç '{IMAGE_BUCKET_NAME}' –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–æ–∑–¥–∞—é –Ω–æ–≤—ã–π –ø—É–±–ª–∏—á–Ω—ã–π –±–∞–∫–µ—Ç...")
        supabase.storage.create_bucket(IMAGE_BUCKET_NAME, options={"public": True})
        logging.info(f"‚úÖ –ë–∞–∫–µ—Ç '{IMAGE_BUCKET_NAME}' —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω.")
    else:
        # –ï—Å–ª–∏ –±–∞–∫–µ—Ç —É–∂–µ –µ—Å—Ç—å, —É–±–µ–¥–∏–º—Å—è, —á—Ç–æ –æ–Ω –ø—É–±–ª–∏—á–Ω—ã–π
        logging.info(f"‚ÑπÔ∏è –ë–∞–∫–µ—Ç '{IMAGE_BUCKET_NAME}' –Ω–∞–π–¥–µ–Ω. –û–±–Ω–æ–≤–ª—è—é –ø—Ä–∞–≤–∞ –Ω–∞ Public...")
        supabase.storage.update_bucket(IMAGE_BUCKET_NAME, {"public": True})
except Exception as e:
    logging.warning(f"‚ö†Ô∏è –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–∫–µ—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {e}")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Gemini
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
else:
    logging.warning("‚ö†Ô∏è GEMINI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ AI –±—É–¥–µ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.")

def clean_query_for_pixabay(text):
    """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–≤–æ–¥–∞ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∏—Å–∫–∞ –∫–∞—Ä—Ç–∏–Ω–æ–∫."""
    if not text: return ""
    # –£–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –≤ —Å–∫–æ–±–∫–∞—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–∂–µ–Ω—â–∏–Ω–∞ (–≤–∑—Ä–æ—Å–ª–∞—è)")
    text = re.sub(r'\(.*?\)', '', text)
    # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é —á–∞—Å—Ç—å –¥–æ –∑–∞–ø—è—Ç–æ–π –∏–ª–∏ —Ç–æ—á–∫–∏ —Å –∑–∞–ø—è—Ç–æ–π
    text = re.split(r'[;,]', text)[0]
    return text.strip()

def clean_text_for_tts(text):
    """–£–¥–∞–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –≤ —Å–∫–æ–±–∫–∞—Ö (Hanja, –ø–æ—è—Å–Ω–µ–Ω–∏—è) –¥–ª—è —á–∏—Å—Ç–æ–≥–æ –æ–∑–≤—É—á–∏–≤–∞–Ω–∏—è."""
    if not text: return ""
    # –£–¥–∞–ª—è–µ–º (—Ç–µ–∫—Å—Ç) –∏ [—Ç–µ–∫—Å—Ç], –≤–∫–ª—é—á–∞—è –ø—Ä–æ–±–µ–ª –ø–µ—Ä–µ–¥ –Ω–∏–º–∏
    text = re.sub(r'\s*[\(\[].*?[\)\]]', '', text)
    return text.strip()

async def delete_old_file(bucket, url):
    """–£–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª –∏–∑ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π –Ω–æ–≤–æ–≥–æ"""
    if not url: return
    try:
        filename = unquote(url.split('/')[-1].split('?')[0])
        loop = asyncio.get_running_loop()
        await loop.run_in_executor(None, lambda: supabase.storage.from_(bucket).remove([filename]))
        logging.info(f"üóë –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª: {filename}")
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª {url}: {e}")

def cleanup_temp_files():
    """–£–¥–∞–ª—è–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ mp3 —Ñ–∞–π–ª—ã, –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∑–∞–ø—É—Å–∫–æ–≤."""
    try:
        for f in os.listdir("."):
            if f.startswith("temp_") and f.endswith(".mp3"):
                try:
                    os.remove(f)
                    logging.info(f"üßπ –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {f}")
                except Exception as e:
                    logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {f}: {e}")
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {e}")

async def generate_edge_tts(text, filepath, voice="ko-KR-SunHiNeural"):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ Microsoft Edge TTS (–±–µ—Å–ø–ª–∞—Ç–Ω–æ, –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ)"""
    clean_text = clean_text_for_tts(text)
    if not clean_text: return False

    for i in range(3): # 3 –ø–æ–ø—ã—Ç–∫–∏ –ø—Ä–∏ –æ—à–∏–±–∫–µ —Å–µ—Ç–∏
        try:
            communicate = edge_tts.Communicate(clean_text, voice)
            await communicate.save(filepath)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞: —Ñ–∞–π–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –±–æ–ª—å—à–µ 0 –±–∞–π—Ç
            if os.path.getsize(filepath) < MIN_FILE_SIZE:
                logging.warning(f"‚ö†Ô∏è –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –º–∞–ª ({os.path.getsize(filepath)}b): {text}")
                return False
                
            return True
        except Exception as e:
            if i == 2: logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Edge TTS: {e}")
            await asyncio.sleep(1)
    return False

async def generate_dialogue_audio(text, filepath):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∏–∞–ª–æ–≥–∞ —Å –¥–≤—É–º—è –≥–æ–ª–æ—Å–∞–º–∏ (A/B –∏–ª–∏ Í∞Ä/ÎÇò) —á–µ—Ä–µ–∑ SSML —Å –ø–∞—É–∑–∞–º–∏"""
    lines = text.replace('\r\n', '\n').split('\n')
    
    voice_female = "ko-KR-SunHiNeural"
    voice_male = "ko-KR-InJoonNeural"
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º SSML —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    ssml_parts = [
        '<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="ko-KR">'
    ]
    
    current_voice = voice_female
    has_content = False
    
    try:
        for line in lines:
            line = line.strip()
            if not line: continue
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–æ–ª–æ—Å–∞
            if re.match(r'^[AaÍ∞Ä]\s*:', line):
                current_voice = voice_female
                line = re.sub(r'^[AaÍ∞Ä]\s*:', '', line).strip()
            elif re.match(r'^[BbÎÇò]\s*:', line):
                current_voice = voice_male
                line = re.sub(r'^[BbÎÇò]\s*:', '', line).strip()
            
            if not line: continue
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—É–∑—É 500–º—Å –ø–µ—Ä–µ–¥ —Ä–µ–ø–ª–∏–∫–æ–π (–∫—Ä–æ–º–µ –ø–µ—Ä–≤–æ–π)
            if has_content:
                 ssml_parts.append('<break time="500ms"/>')
                 
            # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã XML –∏ –æ–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≤ —Ç–µ–≥ –≥–æ–ª–æ—Å–∞
            # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç Hanja –ø–µ—Ä–µ–¥ –≤—Å—Ç–∞–≤–∫–æ–π –≤ SSML
            safe_line = clean_text_for_tts(line).replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
            ssml_parts.append(f'<voice name="{current_voice}">{safe_line}</voice>')
            has_content = True
            
        ssml_parts.append('</speak>')
        
        if not has_content: return False
        
        ssml_string = "".join(ssml_parts)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º SSML –≤ edge-tts
        communicate = edge_tts.Communicate(ssml_string, voice_female)
        await communicate.save(filepath)
        
        if os.path.getsize(filepath) < MIN_FILE_SIZE:
             logging.warning(f"‚ö†Ô∏è –î–∏–∞–ª–æ–≥ —Å–ª–∏—à–∫–æ–º –º–∞–ª: {text[:20]}...")
             return False
             
        return True
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–∏–∞–ª–æ–≥–∞ (SSML): {e}")
        return False

def check_integrity(bucket_name, table_name='vocabulary'):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ —Ñ–∞–π–ª–æ–≤ –∏ —Å—Å—ã–ª–æ–∫ –≤ –ë–î"""
    logging.info(f"üßπ –ó–∞–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –±–∞–∫–µ—Ç–∞ '{bucket_name}'...")
    
    # 1. –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤ –±–∞–∫–µ—Ç–µ
    storage_files = {}
    try:
        offset = 0
        while True:
            res = supabase.storage.from_(bucket_name).list(path=None, options={"limit": 100, "offset": offset})
            if not res: break
            for f in res:
                name = f.get('name') if isinstance(f, dict) else getattr(f, 'name', None)
                size = f.get('metadata', {}).get('size', 0) if isinstance(f, dict) else getattr(f, 'metadata', {}).get('size', 0)
                if name: storage_files[name] = size
            offset += 100
            if len(res) < 100: break
        logging.info(f"üìÇ –§–∞–π–ª–æ–≤ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ: {len(storage_files)}")
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤: {e}")
        return

    # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Å—ã–ª–∫–∏ –≤ –ë–î
    try:
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ (–ø–∞–≥–∏–Ω–∞—Ü–∏—è –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è –¥–ª—è –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö –ë–î)
        rows = []
        offset = 0
        while True:
            res = supabase.table(table_name).select("*").range(offset, offset + 999).execute()
            if not res.data: break
            rows.extend(res.data)
            offset += 1000
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ë–î: {e}")
        return

    referenced_files = set()
    fixed_count = 0

    # –ö–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ñ–∞–π–ª—ã –≤ —ç—Ç–æ–º –±–∞–∫–µ—Ç–µ
    target_cols = ['audio_url', 'audio_male', 'example_audio'] if bucket_name == BUCKET_NAME else ['image']

    for row in rows:
        if not isinstance(row, dict): continue
        row_id = row.get('id')
        updates = {}
        for col in target_cols:
            url = row.get(col)
            if not url or not isinstance(url, str): continue
            
            filename = unquote(url.split('/')[-1].split('?')[0]) # –£–±–∏—Ä–∞–µ–º query params –∏ –¥–µ–∫–æ–¥–∏—Ä—É–µ–º

            # –ü—Ä–æ–≤–µ—Ä–∫–∞: —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –Ω–µ –ø—É—Å—Ç–æ–π (–¥–ª—è –∞—É–¥–∏–æ > 100 –±–∞–π—Ç)
            min_size = 100 if bucket_name == BUCKET_NAME else 0
            
            if filename not in storage_files or storage_files[filename] <= min_size:
                logging.warning(f"‚ö†Ô∏è –ë–∏—Ç–∞—è —Å—Å—ã–ª–∫–∞ –∏–ª–∏ –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª: id={row_id} col={col} file={filename}")
                updates[col] = None # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—Å—ã–ª–∫—É, —á—Ç–æ–±—ã —Å–∫—Ä–∏–ø—Ç –ø–µ—Ä–µ—Å–æ–∑–¥–∞–ª –µ—ë
                if col == 'image':
                    updates['image_source'] = None # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫, —á—Ç–æ–±—ã —Ä–∞–∑—Ä–µ—à–∏—Ç—å –ø–µ—Ä–µ–∑–∞–ø–∏—Å—å
            else:
                referenced_files.add(filename) # –§–∞–π–ª –≤–∞–ª–∏–¥–µ–Ω, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –µ–≥–æ –æ—Ç —É–¥–∞–ª–µ–Ω–∏—è
        
        if updates:
            try:
                supabase.table(table_name).update(updates).eq('id', row_id).execute()
                fixed_count += 1
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è id={row_id}: {e}")

    logging.info(f"‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π –≤ –ë–î: {fixed_count}")

    # 3. –£–¥–∞–ª—è–µ–º —Å–∏—Ä–æ—Ç (—Ñ–∞–π–ª—ã –±–µ–∑ —Å—Å—ã–ª–æ–∫)
    orphans = [f for f in storage_files if f not in referenced_files]
    if orphans:
        logging.info(f"üóë –ù–∞–π–¥–µ–Ω–æ {len(orphans)} –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤. –£–¥–∞–ª–µ–Ω–∏–µ...")
        # –£–¥–∞–ª—è–µ–º –ø–∞—á–∫–∞–º–∏ –ø–æ 10
        for i in range(0, len(orphans), 10):
            batch = orphans[i:i+10]
            try:
                supabase.storage.from_(bucket_name).remove(batch)
                logging.info(f"   –£–¥–∞–ª–µ–Ω–æ: {batch}")
            except Exception as e:
                logging.error(f"   –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è: {e}")
    else:
        logging.info("‚ú® –õ–∏—à–Ω–∏—Ö —Ñ–∞–π–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")

def optimize_image_data(data):
    """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é Pillow"""
    try:
        img = Image.open(BytesIO(data))
        if img.mode != 'RGB':
            img = img.convert('RGB')
        output = BytesIO()
        img.save(output, format='JPEG', quality=80, optimize=True)
        return output.getvalue()
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        return data

if args.check:
    check_integrity(BUCKET_NAME)
    check_integrity(IMAGE_BUCKET_NAME)
    logging.info("üèÅ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ü–µ—Ä–µ—Ö–æ–¥ –∫ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—é –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")

async def upload_to_supabase(bucket, path, data, content_type):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤ Supabase"""
    loop = asyncio.get_running_loop()
    # upsert=True –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞—Ç—å —Ñ–∞–π–ª—ã, –∏–∑–±–µ–≥–∞—è –æ—à–∏–±–æ–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    await loop.run_in_executor(None, lambda: supabase.storage.from_(bucket).upload(
        path=path, file=data, file_options={"content-type": content_type, "upsert": "true"}
    ))

async def update_db_record(row_id, updates):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ë–î"""
    loop = asyncio.get_running_loop()
    await loop.run_in_executor(None, lambda: supabase.table('vocabulary').update(updates).eq("id", row_id).execute())

async def handle_main_audio(session, row, word, word_hash, force_audio=False):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∞—É–¥–∏–æ (–ñ–µ–Ω—Å–∫–∏–π –≥–æ–ª–æ—Å - SunHi)"""
    if row.get('audio_url') and not force_audio: return {}
    
    audio_filename = f"{word_hash}.mp3"
    filepath = f"temp_{audio_filename}"
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º EdgeTTS (SunHi - –ñ–µ–Ω—Å–∫–∏–π)
    if await generate_edge_tts(word, filepath, "ko-KR-SunHiNeural"):
        try:
            if row.get('audio_url'):
                await delete_old_file(BUCKET_NAME, row.get('audio_url'))
            with open(filepath, 'rb') as f:
                await upload_to_supabase(BUCKET_NAME, audio_filename, f, "audio/mpeg")
            url = supabase.storage.from_(BUCKET_NAME).get_public_url(audio_filename)
            logging.info(f"‚úÖ Audio Female: {word}")
            return {'audio_url': url}
        finally:
            if os.path.exists(filepath): os.remove(filepath)
    return {}

async def handle_male_audio(row, word, word_hash, force_audio=False):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –º—É–∂—Å–∫–æ–≥–æ –∞—É–¥–∏–æ (EdgeTTS)"""
    if row.get('audio_male') and not force_audio: return {}
    
    male_filename = f"{word_hash}_M.mp3"
    filepath = f"temp_{male_filename}"
    
    if await generate_edge_tts(word, filepath, "ko-KR-InJoonNeural"):
        try:
            if row.get('audio_male'):
                await delete_old_file(BUCKET_NAME, row.get('audio_male'))
            with open(filepath, 'rb') as f:
                await upload_to_supabase(BUCKET_NAME, male_filename, f, "audio/mpeg")
            url = supabase.storage.from_(BUCKET_NAME).get_public_url(male_filename)
            logging.info(f"‚úÖ Audio Male: {word}")
            return {'audio_male': url}
        finally:
            if os.path.exists(filepath): os.remove(filepath)
    return {}

async def handle_example_audio(row, example, force_audio=False):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ –ø—Ä–∏–º–µ—Ä–∞ (Dialogue/EdgeTTS)"""
    if not example or not isinstance(example, str): return {}
    if row.get('example_audio') and not force_audio: return {}
    
    ex_hash = hashlib.md5(example.encode('utf-8')).hexdigest()
    ex_filename = f"ex_{ex_hash}.mp3"
    filepath = f"temp_{ex_filename}"
    ex_downloaded = False
    
    is_dialogue = re.search(r'(^|\n)[AaBbÍ∞ÄÎÇò]\s*:', example)
    if is_dialogue:
        if await generate_dialogue_audio(example, filepath): ex_downloaded = True
    else:
        if await generate_edge_tts(example, filepath, "ko-KR-SunHiNeural"): ex_downloaded = True
    
    if ex_downloaded:
        try:
            if row.get('example_audio'):
                await delete_old_file(BUCKET_NAME, row.get('example_audio'))
            with open(filepath, 'rb') as f:
                await upload_to_supabase(BUCKET_NAME, ex_filename, f, "audio/mpeg")
            url = supabase.storage.from_(BUCKET_NAME).get_public_url(ex_filename)
            logging.info(f"‚úÖ Example: {example[:10]}...")
            return {'example_audio': url}
        finally:
            if os.path.exists(filepath): os.remove(filepath)
    return {}

async def handle_image(session, row, translation, word_hash, force_images):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (Pixabay)"""
    current_image = row.get('image')
    image_source = row.get('image_source')

    if current_image:
        # –ï—Å–ª–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ –ù–ï 'pixabay' (–∑–Ω–∞—á–∏—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è) ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≤—Å–µ–≥–¥–∞
        if image_source != 'pixabay':
            return {}
        # –ï—Å–ª–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ 'pixabay', –Ω–æ –Ω–µ –≤–∫–ª—é—á–µ–Ω force ‚Äî —Ç–æ–∂–µ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        if not force_images:
            return {}

    # 2. –ï—Å–ª–∏ –¥–æ—à–ª–∏ —Å—é–¥–∞: –ª–∏–±–æ –∫–∞—Ä—Ç–∏–Ω–∫–∏ –Ω–µ—Ç, –ª–∏–±–æ —ç—Ç–æ Pixabay + force
    if not translation or not isinstance(translation, str) or not PIXABAY_API_KEY: return {}
    
    updates = {}
    q = clean_query_for_pixabay(translation)
    
    if not q: return {} # –ù–µ —Ç—Ä–∞—Ç–∏–º –∫–≤–æ—Ç—É –Ω–∞ –ø—É—Å—Ç—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    
    try:
        params = {"key": PIXABAY_API_KEY, "q": q, "lang": "ru", "image_type": "photo", "per_page": 3, "safesearch": "true"}
        async with session.get("https://pixabay.com/api/", params=params) as pix_res:
            if pix_res.status == 200:
                hits = (await pix_res.json()).get('hits')
                if hits:
                    p_url = hits[0]['webformatURL']
                    async with session.get(p_url) as img_res:
                        if img_res.status == 200:
                            fname = f"{word_hash}_pix.jpg" # –£–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
                            img_data = await img_res.read()
                            
                            # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è (–≤—ã–ø–æ–ª–Ω—è–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ, —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å async)
                            loop = asyncio.get_running_loop()
                            optimized_data = await loop.run_in_executor(None, optimize_image_data, img_data)
                            
                            if len(optimized_data) < MIN_FILE_SIZE:
                                logging.warning(f"‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ: {translation}")
                                return {}

                            await upload_to_supabase(IMAGE_BUCKET_NAME, fname, optimized_data, "image/jpeg")
                            
                            public_url = supabase.storage.from_(IMAGE_BUCKET_NAME).get_public_url(fname)
                            updates['image'] = public_url
                            updates['image_source'] = 'pixabay'
                            logging.info(f"‚úÖ Image: {translation}")
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è Pixabay error {translation}: {e}")
    
    return updates

async def _generate_content_for_word(session, row):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è —Å–ª–æ–≤–∞ (–∞—É–¥–∏–æ, –∫–∞—Ä—Ç–∏–Ω–∫–∏)"""
    word = row.get('word_kr')
    translation = row.get('translation')
    example = row.get('example_kr')
    word_hash = hashlib.md5(word.encode('utf-8')).hexdigest()

    tasks = [
        handle_main_audio(session, row, word, word_hash, args.force_audio),
        handle_male_audio(row, word, word_hash, args.force_audio),
        handle_example_audio(row, example, args.force_audio),
        handle_image(session, row, translation, word_hash, args.force_images)
    ]
    
    results = await asyncio.gather(*tasks)
    updates = {}
    for res in results:
        if res: updates.update(res)
    return updates

def _handle_processing_error(e, word, error_counter):
    """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    err_str = str(e).lower()
    if isinstance(e, (aiohttp.ClientError, asyncio.TimeoutError)) or \
       'timeout' in err_str or 'connection' in err_str or 'network' in err_str:
        logging.warning(f"üåê –°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ '{word}': {e}")
        error_counter['network'] += 1
    else:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–ª–æ–≤–∞ '{word}': {e}")
        error_counter['other'] += 1

async def process_word(sem, session, row, error_counter):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Å–ª–æ–≤–∞ (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ)"""
    async with sem: # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
        row_id = row.get('id')
        word = row.get('word_kr')
        
        if not isinstance(row, dict) or not word or not isinstance(word, str):
            return row_id

        try:
            updates_to_make = await _generate_content_for_word(session, row)
            
            if updates_to_make:
                await update_db_record(row_id, updates_to_make)
                return None # –£—Å–ø–µ—Ö
            else:
                return row_id
        except Exception as e:
            _handle_processing_error(e, word, error_counter)
            return row_id

async def process_word_request(request):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞—è–≤–∫–∏ –Ω–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ª–æ–≤–∞ —á–µ—Ä–µ–∑ AI"""
    req_id = request.get('id')
    word_kr = request.get('word_kr')
    user_id = request.get('user_id')
    
    if not word_kr or not GEMINI_API_KEY:
        return

    logging.info(f"ü§ñ AI –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å: {word_kr}")

    try:
        # 1. –ó–∞–ø—Ä–æ—Å –∫ Gemini –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
        prompt = f"""
        Analyze the Korean word '{word_kr}'. Return a JSON object with the following fields:
        - word_kr: the word itself (corrected if needed)
        - translation: Russian translation (concise)
        - word_hanja: Hanja characters (if applicable, else empty string)
        - topic: A relevant topic category in format "Topic (–¢–µ–º–∞)" (e.g. "School (–®–∫–æ–ª–∞)")
        - category: Part of speech in format "Noun (–°—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ)" etc.
        - level: TOPIK level (e.g. "‚òÖ‚òÜ‚òÜ", "‚òÖ‚òÖ‚òÜ", "‚òÖ‚òÖ‚òÖ") based on difficulty
        - example_kr: A simple Korean example sentence using the word
        - example_ru: Russian translation of the example
        - synonyms: Comma-separated synonyms (Korean)
        - antonyms: Comma-separated antonyms (Korean)
        - type: "word" or "grammar" (usually "word")
        
        Ensure the response is valid JSON.
        """
        
        response = await asyncio.to_thread(
            genai.GenerativeModel('gemini-pro').generate_content,
            contents=prompt
        )
        text_response = response.text
        
        if not text_response:
            logging.error(f"‚ùå –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç AI –¥–ª—è {word_kr}")
            return
        
        # –û—á–∏—Å—Ç–∫–∞ –æ—Ç markdown ```json ... ```
        if "```json" in text_response:
            text_response = text_response.split("```json")[1].split("```")[0]
        elif "```" in text_response:
            text_response = text_response.split("```")[1].split("```")[0]
            
        data = json.loads(text_response.strip())
        
        # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ vocabulary
        # –ï—Å–ª–∏ —Å–ª–æ–≤–æ —É–∂–µ –µ—Å—Ç—å, –º—ã –º–æ–∂–µ–º –ø—Ä–æ—Å—Ç–æ –æ–±–Ω–æ–≤–∏—Ç—å –µ–≥–æ –∏–ª–∏ –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å
        # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã, –µ—Å–ª–∏ —Å–ª–æ–≤–æ –µ—Å—Ç—å, –º—ã –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç, –∞ –ø—Ä–æ—Å—Ç–æ –ø–æ–º–µ—á–∞–µ–º –∑–∞—è–≤–∫—É –∫–∞–∫ processed
        existing = supabase.table('vocabulary').select('id').eq('word_kr', data['word_kr']).execute()
        
        word_id = None
        existing_data = getattr(existing, 'data', None)
        
        if existing_data and isinstance(existing_data, list) and len(existing_data) > 0:
            logging.info(f"‚ÑπÔ∏è –°–ª–æ–≤–æ {data.get('word_kr')} —É–∂–µ –µ—Å—Ç—å –≤ –±–∞–∑–µ.")
            word_id = existing_data[0]['id']
        else:
            # 3. –í—Å—Ç–∞–≤–∫–∞ –≤ vocabulary
            # –ï—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ, —á—Ç–æ–±—ã —Å–ª–æ–≤–æ –±—ã–ª–æ –≤–∏–¥–Ω–æ –¢–û–õ–¨–ö–û –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é, –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–ª–µ user_id –≤ vocabulary
            # –°–µ–π—á–∞—Å —Å—Ö–µ–º–∞ vocabulary –æ–±—â–∞—è. –î–æ–±–∞–≤–∏–º —Å–ª–æ–≤–æ –∫–∞–∫ –æ–±—â–µ–µ.
            insert_res = supabase.table('vocabulary').insert(data).execute()
            insert_data = getattr(insert_res, 'data', None)
            
            if insert_data and isinstance(insert_data, list) and len(insert_data) > 0:
                word_id = insert_data[0]['id']
                logging.info(f"‚úÖ –°–ª–æ–≤–æ {data.get('word_kr')} –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ —Å–ª–æ–≤–∞—Ä—å.")
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –º–µ–¥–∏–∞ –¥–ª—è –Ω–æ–≤–æ–≥–æ —Å–ª–æ–≤–∞ —Å—Ä–∞–∑—É
                # FIX: –ó–∞—Ö–≤–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –≤ –ë–î
                async with aiohttp.ClientSession() as session:
                    updates = await _generate_content_for_word(session, insert_data[0])
                    if updates:
                        await update_db_record(word_id, updates)

        # 4. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞—è–≤–∫–∏
        supabase.table('word_requests').update({'status': 'processed'}).eq('id', req_id).execute()
        
        # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –î–æ–±–∞–≤–∏—Ç—å —Å–ª–æ–≤–æ –≤ "–ò–∑—É—á–∞–µ–º—ã–µ" –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∫–æ—Ç–æ—Ä—ã–π –µ–≥–æ –∑–∞–ø—Ä–æ—Å–∏–ª
        if word_id and user_id:
             try:
                 supabase.table('user_progress').upsert({'user_id': user_id, 'word_id': word_id, 'is_learned': False}).execute()
             except Exception as e:
                 logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –≤ –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {e}")

    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ AI –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è {word_kr}: {e}")
        supabase.table('word_requests').update({'status': 'error'}).eq('id', req_id).execute()

async def measure_network_quality():
    """–ò–∑–º–µ—Ä—è–µ—Ç –∑–∞–¥–µ—Ä–∂–∫—É —Å–µ—Ç–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤."""
    logging.info("üì° –ê–Ω–∞–ª–∏–∑ —Å–∫–æ—Ä–æ—Å—Ç–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è...")
    test_url = "https://www.google.com"
    start = time.time()
    try:
        async with aiohttp.ClientSession() as session:
            # –î–µ–ª–∞–µ–º 3 –ª–µ–≥–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è
            for _ in range(3):
                async with session.get(test_url, timeout=aiohttp.ClientTimeout(total=5)) as response:
                    await response.read()
        
        duration = time.time() - start
        avg_latency = duration / 3
        
        logging.info(f"‚è± –°—Ä–µ–¥–Ω–∏–π –æ—Ç–∫–ª–∏–∫: {avg_latency:.3f} —Å–µ–∫.")
        
        if avg_latency < 0.15: return 25 # –û—Ç–ª–∏—á–Ω—ã–π –∏–Ω—Ç–µ—Ä–Ω–µ—Ç
        if avg_latency < 0.30: return 15 # –•–æ—Ä–æ—à–∏–π
        if avg_latency < 0.60: return 8  # –°—Ä–µ–¥–Ω–∏–π
        if avg_latency < 1.00: return 4  # –ú–µ–¥–ª–µ–Ω–Ω—ã–π
        return 2 # –û—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω—ã–π
        
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–º–µ—Ä–∏—Ç—å —Å–∫–æ—Ä–æ—Å—Ç—å ({e}). –ò—Å–ø–æ–ª—å–∑—É—é –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (5).")
        return 5

async def main_loop():
    logging.info("üöÄ –í–æ—Ä–∫–µ—Ä –∑–∞–ø—É—â–µ–Ω (Async Mode).")
    
    concurrency = args.concurrency
    if concurrency == 0:
        concurrency = await measure_network_quality()
        logging.info(f"‚ö° –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ—Ç–æ–∫–æ–≤: {concurrency}")
    
    # –õ–æ–∫–∞–ª—å–Ω—ã–π –∫—ç—à –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º—ã—Ö ID (—á—Ç–æ–±—ã –Ω–µ –¥–æ–ª–±–∏—Ç—å –æ–¥–Ω–∏ –∏ —Ç–µ –∂–µ –æ—à–∏–±–∫–∏)
    ignore_ids = set()

    while True:
        try:
            cleanup_temp_files()
            
            # 0. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞—è–≤–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (Word Requests)
            if GEMINI_API_KEY:
                try:
                    reqs = supabase.table('word_requests').select("*").eq('status', 'pending').limit(5).execute()
                    for req in reqs.data:
                        await process_word_request(req)
                except Exception as e:
                    logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞—è–≤–æ–∫: {e}")

            # –ó–∞–ø—Ä–æ—Å –∫ –ë–î (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π, –Ω–æ –±—ã—Å—Ç—Ä—ã–π)
            try:
                if args.force_images or args.force_audio:
                    query = supabase.table('vocabulary').select("*")
                else:
                    # –ë–µ—Ä–µ–º –±–æ–ª—å—à–µ —Å–ª–æ–≤ –∑–∞ —Ä–∞–∑ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
                    query = supabase.table('vocabulary').select("*").or_("audio_url.is.null,audio_male.is.null,image.is.null,example_audio.is.null").limit(200)
                
                if args.topic:
                    query = query.ilike("topic", f"%{args.topic}%")

                response = query.execute()
                words = response.data or []
                # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –ø—ã—Ç–∞–ª–∏—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏ –Ω–µ —Å–º–æ–≥–ª–∏
                words = [w for w in words if isinstance(w, dict) and w.get('id') not in ignore_ids]
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ë–î: {e}")
                words = []

            if not words:
                if not args.force_images and not args.force_audio:
                    logging.info("üí§ –ù–µ—Ç –Ω–æ–≤—ã—Ö —Å–ª–æ–≤. –ñ–¥—É 60 —Å–µ–∫...")
                    await asyncio.sleep(60)
                else:
                    logging.info("üèÅ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ (force mode).")
                    break
                continue

            logging.info(f"üî• –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {len(words)} —Å–ª–æ–≤... (–ü–æ—Ç–æ–∫–æ–≤: {concurrency})")
            
            sem = asyncio.Semaphore(concurrency)
            error_counter = {'network': 0, 'other': 0}

            async with aiohttp.ClientSession() as session:
                tasks = [process_word(sem, session, row, error_counter) for row in words]
                results = await asyncio.gather(*tasks)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ ID –≤ —Å–ø–∏—Å–æ–∫ –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è
                for res in results:
                    if res: ignore_ids.add(res)
                
                await asyncio.sleep(0.1) # Yield to event loop to prevent socket starvation on Windows
            
            # --- –õ–æ–≥–∏–∫–∞ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ—Å—Ç–∏ ---
            batch_size = len(words)
            if batch_size > 0:
                network_error_rate = (error_counter['network'] / batch_size) * 100
                
                # –°–Ω–∏–∂–∞–µ–º, –µ—Å–ª–∏ >15% –∑–∞–¥–∞—á –≤ –ø–∞—á–∫–µ —É–ø–∞–ª–∏ —Å —Å–µ—Ç–µ–≤–æ–π –æ—à–∏–±–∫–æ–π
                if network_error_rate > 15.0:
                    new_concurrency = max(1, int(concurrency * 0.7)) # –£–º–µ–Ω—å—à–∞–µ–º –Ω–∞ 30%
                    if new_concurrency < concurrency:
                        logging.warning(f"üìâ –í—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å —Å–µ—Ç–µ–≤—ã—Ö –æ—à–∏–±–æ–∫ ({network_error_rate:.1f}%). –°–Ω–∏–∂–∞—é –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ —Å {concurrency} –¥–æ {new_concurrency}.")
                        concurrency = new_concurrency
                # –ü–æ–≤—ã—à–∞–µ–º, –µ—Å–ª–∏ –Ω–µ –±—ã–ª–æ –æ—à–∏–±–æ–∫ –∏ –º—ã –Ω–µ –Ω–∞ –º–∞–∫—Å–∏–º—É–º–µ
                elif error_counter['network'] == 0 and concurrency < 25:
                    new_concurrency = min(25, concurrency + 1) # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –Ω–∞ 1
                    if new_concurrency > concurrency:
                        logging.info(f"üìà –°–µ—Ç—å —Å—Ç–∞–±–∏–ª—å–Ω–∞. –£–≤–µ–ª–∏—á–∏–≤–∞—é –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ –¥–æ {new_concurrency}.")
                        concurrency = new_concurrency

            logging.info(f"‚ú® –ü–∞—á–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞. –ü—Ä–æ–±–ª–µ–º–Ω—ã—Ö –≤ —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏: {len(ignore_ids)}")

        except Exception as main_e:
            logging.error(f"üî• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —Ü–∏–∫–ª–∞: {main_e}")
            await asyncio.sleep(60)

if __name__ == "__main__":
    try:
        # FIX: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è Windows (WinError 10035)
        if sys.platform == 'win32':
            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
            
        asyncio.run(main_loop())
    except KeyboardInterrupt:
        logging.info("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤–æ—Ä–∫–µ—Ä–∞.")
